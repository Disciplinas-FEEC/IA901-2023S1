{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organização do conjunto de dados LBPA40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mover os arquivos que serão utilizados no treinamento e validação:\n",
    "* Neste código apenas os arquivos das imagens e segmentações em nifti foram separados para facilitar o treinamento. Para as imagens o padrão utilizado foi \"native.mri\" e para as mascaras \"native.brain.mask.nii.gz\". Os arquivos foram transferidos para \"organized_dataset/LBPA40\" usando para cada sujeito o mesmo nome das pastas de origem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S12\n",
      "S40\n",
      "S20\n",
      "S38\n",
      "S34\n",
      "S28\n",
      "S05\n",
      "S03\n",
      "S39\n",
      "S08\n",
      "S15\n",
      "S37\n",
      "S33\n",
      "S36\n",
      "S16\n",
      "S23\n",
      "S31\n",
      "S07\n",
      "S04\n",
      "S11\n",
      "S14\n",
      "S01\n",
      "S01\n",
      "S26\n",
      "S02\n",
      "S24\n",
      "S19\n",
      "S09\n",
      "S17\n",
      "S10\n",
      "S25\n",
      "S32\n",
      "S22\n",
      "S06\n",
      "S18\n",
      "S13\n",
      "S30\n",
      "S27\n",
      "S21\n",
      "S29\n",
      "S35\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "file_paths = list(glob.iglob(\"/home/joany/brain_dataset/raw_dataset/LBPA40/*/*native.mri.nii.gz\", recursive=True)) \n",
    "for data_path in file_paths:\n",
    "    patient_id = os.path.dirname(data_path)\n",
    "    patient_id = patient_id.split('/')[-1]\n",
    "    print(patient_id)\n",
    "    \n",
    "    os.makedirs(\"/home/joany/brain_dataset/organized_dataset/LBPA40/\" + patient_id, exist_ok=True)\n",
    "    try:\n",
    "        shutil.copy(data_path, \"/home/joany/brain_dataset/organized_dataset/LBPA40/\" + patient_id)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mudar o nome dos arquivos \n",
    "* Aqui os os nomes dos arquivos foram mudados. os da imagem foram mudados de \"native.mri.nii.gz\" para \"brain_T1w.nii.gz\" e os das segmentações de \"native.brain.mask.nii.gz\" para \"brainmask_T1w.nii.gz\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo S12.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S40.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S20.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S38.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S34.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S28.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S05.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S03.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S39.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S08.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S15.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S37.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S33.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S36.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S16.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S23.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S31.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S07.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S04.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S11.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S14.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S01.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S26.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S02.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S24.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S19.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S09.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S17.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S10.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S25.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S32.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S22.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S06.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S18.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S13.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S30.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S27.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S21.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S29.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n",
      "Arquivo S35.native.mri.nii.gz foi renomeado para brain_T1w.nii.gz.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def padronizar_nomes_pasta(caminho_pasta):\n",
    "    \n",
    "    subjects = glob.glob(os.path.join(caminho_pasta, \"*\"))\n",
    "    \n",
    "    for subject in subjects:\n",
    "        if os.path.isdir(subject):\n",
    "            arquivos = glob.glob(os.path.join(subject, '*native.mri.nii.gz'))\n",
    "            \n",
    "            for caminho_completo in arquivos:\n",
    "                if os.path.isfile(caminho_completo):\n",
    "                    novo_nome = 'brain_T1w.nii.gz'\n",
    "                    novo_caminho = os.path.join(subject, novo_nome)\n",
    "                    os.rename(caminho_completo, novo_caminho)\n",
    "                    print(f\"Arquivo {os.path.basename(caminho_completo)} foi renomeado para {novo_nome}.\")\n",
    "\n",
    "pasta = \"/home/joany/brain_dataset/organized_dataset/LBPA40\"\n",
    "padronizar_nomes_pasta(pasta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separa em treino e validação e teste\n",
    "* Aqui o conjunto todo foi separado em treinamento (70%), validação (20%) e teste (10%). A criação das pastas, transferências dos dados e divisão foram feitos automaticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Caminho da pasta original com os dados\n",
    "pasta_origem = \"/home/joany/brain_dataset/organized_dataset/LBPA40\"\n",
    "\n",
    "# Caminho da pasta de destino\n",
    "pasta_destino = \"/home/joany/brain_dataset/split_dataset/LBPA40\"\n",
    "\n",
    "# Criar as pastas de treinamento, validação e teste\n",
    "pasta_treinamento = os.path.join(pasta_destino, \"train\")\n",
    "pasta_validacao = os.path.join(pasta_destino, \"val\")\n",
    "pasta_teste = os.path.join(pasta_destino, \"test\")\n",
    "os.makedirs(pasta_treinamento, exist_ok=True)\n",
    "os.makedirs(pasta_validacao, exist_ok=True)\n",
    "os.makedirs(pasta_teste, exist_ok=True)\n",
    "\n",
    "# Lista para armazenar os nomes das pastas\n",
    "nomes_pastas = []\n",
    "\n",
    "# Percorrer todas as pastas na pasta original\n",
    "for nome_pasta in os.listdir(pasta_origem):\n",
    "    caminho_pasta = os.path.join(pasta_origem, nome_pasta)\n",
    "    if os.path.isdir(caminho_pasta):\n",
    "        nomes_pastas.append(nome_pasta)\n",
    "\n",
    "# Definir divisão em treinamento, validação e teste\n",
    "proporcao_treinamento = 0.7\n",
    "proporcao_validacao = 0.2\n",
    "proporcao_teste = 0.1\n",
    "\n",
    "# Dividir em treinamento, validação e teste\n",
    "nomes_treinamento, nomes_temp = train_test_split(nomes_pastas, train_size=proporcao_treinamento, random_state=42)\n",
    "nomes_validacao, nomes_teste = train_test_split(nomes_temp, train_size=proporcao_validacao/(proporcao_validacao + proporcao_teste), random_state=42)\n",
    "\n",
    "# Mover as pastas selecionadas para o treinamento para a pasta de treinamento\n",
    "for nome_pasta in nomes_treinamento:\n",
    "    origem_pasta = os.path.join(pasta_origem, nome_pasta)\n",
    "    destino_pasta = os.path.join(pasta_treinamento, nome_pasta)\n",
    "    shutil.move(origem_pasta, destino_pasta)\n",
    "\n",
    "# Mover as pastas selecionadas para a validação para a pasta de validação\n",
    "for nome_pasta in nomes_validacao:\n",
    "    origem_pasta = os.path.join(pasta_origem, nome_pasta)\n",
    "    destino_pasta = os.path.join(pasta_validacao, nome_pasta)\n",
    "    shutil.move(origem_pasta, destino_pasta)\n",
    "\n",
    "# Mover as pastas selecionadas para o teste para a pasta de teste\n",
    "for nome_pasta in nomes_teste:\n",
    "    origem_pasta = os.path.join(pasta_origem, nome_pasta)\n",
    "    destino_pasta = os.path.join(pasta_teste, nome_pasta)\n",
    "    shutil.move(origem_pasta, destino_pasta)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "73410407538b4d1a0a852b396975eee7810ded8ec78d6fe740da53f5e1054182"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
