# `Segmenta√ß√£o do c√©rebro usando imagens T1`
# `Brain Segmentation on T1 images`

## Apresenta√ß√£o

O presente projeto foi originado no contexto das atividades da disciplina de p√≥s-gradua√ß√£o *IA901 - Processamento de Imagens e Reconhecimento de Padr√µes*, oferecida no primeiro semestre de 2023, na Unicamp, sob supervis√£o da Profa. Dra. Leticia Rittner, do Departamento de Engenharia de Computa√ß√£o e Automa√ß√£o (DCA) da Faculdade de Engenharia El√©trica e de Computa√ß√£o (FEEC).

|Nome  | RA | Curso|
|--|--|--|
| Jimi Togni           | 226359   | Doutorado em Engenharia El√©trica |
| Joany Rodrigues      | 264440   | Mestrado em Engenharia El√©trica  |
| Victor Praxedes Rael | 240242   | Mestrado em Engenharia El√©trica  |

## Descri√ß√£o do Projeto

Muitos desafios na √°rea de imagem m√©dica exigem como pr√©-processamento a segmenta√ß√£o do c√©rebro, por exemplo, a realiza√ß√£o de registro e segmenta√ß√£o de estruturas cerebrais. Muitas propostas tem surgindo para solucionar este problema, o que j√° tem boas propostas na literatura, por exemplo, o trabalho por [LUCENA, Oeslle et al.](https://ieeexplore.ieee.org/abstract/document/8363766?casa_token=Y9VwrDbJQJ8AAAAA:7MsKQIPK9IAl2PD8zla2eRkO2jNtqUilIMtqGjEBGlRb_P9SNNJkXwgJR91otfmY_wGeJSfhGJg). 

Tem surgido propostas na literatura mostrando que ao aplicar t√©cnicas de pr√©-processamento e aumento de dados pode ser mais vantajoso do que apenas usar t√©cnicas de √∫ltima gera√ß√£o. Por exemplo, a implementa√ß√£o do framework [nnU-Net](https://www.nature.com/articles/s41592-020-01008-z), que busca o melhor pr√©-processamento de um conjunto de dados e hiperpar√¢metros da rede para este conjunto de dados, automaticamente. O objetivo deste framework √© usar a arquitetura de uma CNN simples [U-Net](https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28) para buscar de maneira aut√¥noma o melhor modelo de segmenta√ß√£o de objetos de acordo com as caracter√≠sticas dos dados. Logo, este framework foi executado com o objetivo de adquirir os pr√©-processamentos dos conjuntos de dados usados neste trabalho e usar como ponto de partida para o treinamento 3D deste projeto.

Logo, o objetivo deste projeto √© usar partes de um conjunto de dados de segmenta√ß√£o do c√©rebro para executar um experimento na nnU-Net e obter suas sugest√µes de p≈ïe-processamento de dados e par√¢metros da rede para estud√°-los e definir os mais intuitiv√©is e fact√≠veis, para em seguida, desenvolver um m√©todo de segmenta√ß√£o do c√©rebro usando uma vers√£o da arquitetura U-Net. Este estudo inclu√≠ averiguar quais dos pr√©-processamentos dos dados s√£o vi√°veis para a melhoria de um modelo de segmenta√ß√£o do c√©rebro.

## Bases de Dados e Evolu√ß√£o

Base de Dados | Endere√ßo na Web | Resumo descritivo
------------- | --------------- | -----------------
LBPA40 | [link de acesso](https://www.loni.usc.edu/research/atlas_downloads) | este conjunto de dados √© p√∫blico e cont√©m dados de 40 sujeitos. Dentre outros arquivos, este conjunto de dados cont√©m as imagens ponderadas em T1 e segmenta√ß√µes manuais do c√©rebro tamb√©m em T1. Esse conjunto de dados foi fornecido por um membro do grupo MICLab. Os dados originais est√£o no formato mri.img.gz, por√©m os dados fornecidos para este estudo j√° se encontrava no formato nifti. A convers√£o de img.gz para NIfTI foi feita usando o software [ITKSnap](http://www.itksnap.org/pmwiki/pmwiki.php?n=Documentation.TutorialSectionInstallation). Para a organiza√ß√£o desses dados, foi feito a separa√ß√£o apenas dos arquivos que foram usados neste trabalho (imagens e segmenta√ß√£o do c√©rebro); em seguida renomeamos estes arquivos para brainmask_T1w (segmenta√ß√£o do c√©rebro) e brain_T1w (imagem do c√©rebro) e ent√£o realizamos a divis√£o deste dataset em treinamento (70%), valida√ß√£o (20%) e teste (10%). Detalhes para esta organiza√ß√£o est√£o no notebook [organiza√ß√£o dos dados LBPA40](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/notebooks/data_organization/LBPA40_dataset_organization.ipynb). 
CC359 | [link de acesso](https://portal.conp.ca/dataset?id=projects/calgary-campinas) | este √© um conjunto de dados de resson√¢ncia magn√©tica cerebral desenvolvido por pesquisadores da universidade de Calgary e Unicamp (MICLab). √â composto por imagens de RM do c√©rebro ponderadas em T1 e m√°scaras de segmenta√ß√£o do c√©rebro tamb√©m em T1. Cont√©m 359 sujeitos todos com segmenta√ß√£o padr√£o-prata gerada a partir de um consenso entre segmenta√ß√µes obtidas por pelo menos 3 ferramentas (STAPLE). Apenas 12 sujeitos desses conjunto de dados cont√©m m√°scaras manuais geradas por um especialista. Este conjunto de dados foi adquirido no formato NIfTI e em dois diret√≥rios: um onde continham todas as imagens de todos os sujeito (original) e outro com todas as m√°scaras de todos os sujeitos (staple). Novamente, este conjunto de dados foi fornecido por um membro do grupo MICLab. A partir dos dados fornecidos n√£o foi poss√≠vel identificar os dados que continham segmenta√ß√£o manual. Para isso, foi preciso baixar os dados com anota√ß√£o manual do site e identificar os sujeitos com anota√ß√µes manuais, para separ√°-los manualmente e utiliz√°-los para teste final do modelo. Tamb√©m, foi preciso separar os dados de cada sujeito em pastas (uma pasta para cada sujeito) com as imagens e as m√°scaras. Em seguida as imagens foram renomeadas para brain_T1w e as segmenta√ß√µes para brainmask_T1w. Por fim foi feito a divis√£o dos dados sem anota√ß√£o manual (347 sujeitos) em treinamento (80%) e valida√ß√£o (20%). Detalhes da organiza√ß√£o desse conjunto de dados est√£o no notebook [organiza√ß√£o dos dados CC359](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/notebooks/data_organization/CC359_dataset_organization.ipynb).
NFBS | [link de acesso](http://preprocessed-connectomes-project.org/NFB_skullstripped/) | √© um dataset com 125 resson√¢ncias magn√©ticas anat√¥micas ponderadas em T1 que tem anota√ß√µes manuais do c√©rebro. Este conjunto de dados fornece 3 arquivos para cada sujeito: Structural T1-weighted anonymized image, Skull-stripped image, Brain mask. (FALTA DESCREVER COMO FOI FEITA A ORGANIZ√á√ÉO DESTE CONJUNTO DE DADOS)
IBSR | [link de acesso](https://www.nitrc.org/projects/ibsr) | este conjunto de dados √© um reposit√≥rio de segmenta√ß√£o cerebral da internet (IBSR, do ingl√™s Internet Brain Segmentation Repository) que fornece anota√ß√µes manuais, juntamente com dados de imagem cerebral por resson√¢ncia magn√©tica em T1. Cont√©m 18 sujeitos, todos com anota√ß√µes manuais. Novamente adquiridos por um membro do MICLab. No entanto, os dados est√£o com incompatibilidade, uma vez que as anota√ß√µes manuais n√£o est√£o alinhadas com as imagens. Por isso e para tentar corrigir isto, todo o conjunto de dados foi reservado para teste final. Os arquivos das imagens e m√°scaras foram transferidos para outro diret√≥rio e em seguida as imagens foram renomeadas para  brain_T1w e as segmenta√ß√µes para brainmask_T1w. Detalhes da organiza√ß√£o desse conjunto de dados est√£o no notebook [organiza√ß√£o dos dados IBSR](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/notebooks/data_organization/IBSR_dataset_organization.ipynb).

Detatalhes importantes sobre os conjuntos de dados e sua organiza√ß√£o:
* Todos os conjuntos de dados originais est√£o no formato NIfTI.
* A organiza√ß√£o dos dados foi feita separadamente para cada conjunto de dados. Isso porque os conjuntos de dados eram muito diferentes e nos perdemos ao tentar implementar um √∫nico c√≥digo para organizar e separar em treinamento valida√ß√£o e teste automaticamente. Al√©m disso, alguns passos simples foram feitos manualmente como, criar pastas para cada conjunto de dados ou separar os dados com anota√ß√µes manuais do conjunto de dados CC359.
* Para o treinamento da nn-Unet n√£o foram usados todos os conjuntos de dados, pois ainda est√°vamos muito perdidos nessa organiza√ß√£o, foram usados apenas xx sujeitos. Ainda, foi preciso organizar os dados da maneira que o framework exige, consulte o [tutorial da nnU-Net](https://github.com/MIC-DKFZ/nnUNet/tree/master). Em seguida, as anota√ß√µes foram binarizadas usando limiariza√ß√£o de 0.5, uma vez que os dados adquiridos estavam com as m√°scaras de tipo float (entre 0 e 1) nas bordas e este framework n√£o permite m√°scaras com labels que n√£o cont√™m valores inteiros. A implementa√ß√£o para isso est√° no notebook [organizar de dados para executar a nnU-Net](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/notebooks/data_organization/organizar_dados_nnUNet.ipynb).

## Metodologia
### Arquitetura U-Net
Este trabalho utilizou a arquitetura [U-Net](https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28), uma rede neural convolucional bastante utilizada para segmenta√ß√£o de imagens m√©dicas. Utilizamos as vers√µes 2D e 3D da [U-Net modificada](https://link.springer.com/chapter/10.1007/978-3-030-72084-1_38), conforme implementado por Carmo et al. (2020). 

![U-Net modificada: a resolu√ß√£o espacial √© reduzida pela segunda convolu√ß√£o de cada n√≠vel do codificador; os blocos verde se referem as caracter√≠sticas filtradas pela opera√ß√£o de self attention; cada n√≠vel do codificador e decodificador (blocos de duas convolu√ß√µes) possui conex√£o residual realizando a conex√£o da entrada da primeira convolu√ß√£o √† sa√≠da da segunda convolu√ß√£o (seta em laranja).](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/assets/Unet-IA901A.png)

Muda√ßas da U-Net modificada em rela√ß√£o a original inclui: a utiliza√ß√£o de convolu√ß√µes stride para a redu√ß√£o da resolu√ß√£o espacial em vez de opera√ß√µes de agrega√ß√£o; adi√ß√£o de [conex√£o residual](https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html) propagando a entrada √† sa√≠da de cada n√≠vel do codificador (utilizando soma e uma convolu√ß√£o com kernel de 1 √ó 1 (seta laranja) realizando adapta√ß√£o de canal e resolu√ß√£o espacial e adi√ß√£o de uma opera√ß√£o [self attention](http://proceedings.mlr.press/v102/gorriz19a.html) para filtrar as caracter√≠sticas produzidas em cada n√≠vel do codificador.

Modifica√ß√µes entre as vers√µes 2D e 3D inclui: o n√∫mero de canais de entrada para a vers√£o 3D √© reduzido devido ao aumento da dimensionalidade da variante 3D, uma vez que cada volume √© considerado um canal, enquanto para a vers√£o 2D cada fatia de um volume √© considerado um canal; utiliza√ß√£o de normaliza√ß√£o de inst√¢ncia para a vers√£o 3D, comumente usada em redes convolucionais 3D com batch pequeno e a normaliza√ß√£o em lote para a vers√£o 2D, pois o tamanho do batch √© consideravelmente maior e costuma funcionar bem neste caso quando utiliza convolu√ß√µes 2D.

### Pr√©-Processamento de dados
#### nnU-Net 
Os dados foram executados no framework nnU-Net apenas para obtermos sugest√µes de pr√©-processamento dos dodos e par√¢metros da rede. Para a execus√£o dos dados na nnU-Net, foi necess√°rio organizar os dados da forma que esta exige. A implementa√ß√£o usada para organiza√ß√£o no conjunto de dados usados neste trabalho pode ser encontrado no notebook [organizar de dados para executar a nnU-Net](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/notebooks/data_organization/organizar_dados_nnUNet.ipynb), para mais informa√ß√µes acesse o tutorial do framework. 

Ao executarmos os dados na nnU-Unet, esta forneceu um problema nas segmenta√ß√µes anotadas, uma vez que as essas n√£o era bin√°rias (continham valores entre 0 e 1) e este framework n√£o aceita labels que n√£o sejam num√©ros inteiros. Isso foi importante para sabermos que as segmenta√ß√µes dos dados n√£o estavam binarizadas. Isso foi corrigido para execu√ß√£o da nnU-Net usando o c√≥digo presente tamb√©m no notebook [organizar de dados para executar a nnUNet](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/notebooks/data_organization/organizar_dados_nnUNet.ipynb).

Ap√≥s a execu√ß√£o da nnU-Net, foi obtido uma [lista de pr√©-processamento](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/assets/debug.json) do treinamento 3D e 2D realizado pelo framework. A partir dessa lista, consideramos os seguintes pr√©-processamentos para o treinamento das duas vers√µes da arquitetura U-Net (2D e 3D):

#### Defini√ß√£o de Pr√©-processamentos
* [Redimensionamento de voxel](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/notebooks/pre-processing/voxel_interpolation.ipynb) (spacing): redimensionamento de voxel √© interpolar o voxel para mudar seu tamanho, o que influencia diretamente na resolu√ß√£o da imagem. Isso modifica significativamente os dados chegando a introduzir ru√≠do a partir da interpola√ß√£o. No entando, al√©m de ter sido sugerido pelo framewark, este trabalho usa 4 conjunto de dados diferentes e para manter os voxels de todos os dados padronizados foi feito a interpola√ß√£o de voxel, mantendo todos os volumes de treinamento e valida√ß√£o isom√©tricos com tamanho de voxel igual a 1. Observe que a sujest√£o da nnU-Net foi de [1.0, 0.9999008178710938, 1.0], mas foi usado [1.0, 1.0, 1.0] para deixar os dados isom√©tricos. A tabela abaixo resume o tamanho de voxel e resolu√ß√£o dados de cada conjunto de dados antes e ap√≥s a interpola√ß√£o de voxel.

|Aquisi√ß√£o| Tam. Vox. original (ùëöùëö^3) | Tam. Vox. Iso (ùëöùëö^3) | resolu√ß√£o original | resolu√ß√£o c/ Interpola√ß√£o de Voxel |
|---------|---------------------------|-----------------------|--------------------|-----------------------|
| CC359   | 1 x 1 x 1                 | 1 x 1 x 1             | 171 x 256 x 256    | 171 x 256 x 256 |
| LBPA40  | 0.8594 x 1.5 x 0.8594     | 1 x 1 x 1             | 256 x 124 x 256    | 220 x 186 x 120 |
| NFBS    | 1 x 1 x 0.9999            | 1 x 1 x 1             |  256 x 256 x 192   | 256 x 256 x 192 |
| IBSR    | 0.9375 x 0.9375 x 1.5     | 1 x 1 x 1             |  256 x 256 x 128   | - |

* [Normaliza√ß√£o](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/notebooks/pre-processing/data_normalization.ipynb): a normaliza√ß√£o sugerida pelo framework foi a Z-Score Normalization 'ZScoreNormalization'. Essa √© uma t√©cnica utilizada para transformar os valores de uma vari√°vel para que tenham m√©dia zero e desvio padr√£o igual a 1. Bastante utilizada quando se tem vari√°veis que t√™m escalas diferente, deixando as vari√°veis em uma escala compat√≠vel ou compar√°vel. Em MRIs, para a realiza√ß√£o dessa normaliza√ß√£o a imagem √© subtra√≠da de sua m√©dia e essa opera√ß√£o √© dividida pelo desvio padr√£o da imagem: 

$$ X_{nor} =  (X - \mu) / (\sigma$)$$

Onde X √© a matriz (volume); $\mu$ √© a m√©dia da matriz ($mean(X)$); e $\sigma$ √© o desvio padr√£o da matriz ($std(X)$). Essa normaliza√ß√£o resulta em m√©dia igual a 0 e desvio padr√£o igual a 1.

* [Convers√£o para o npz](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/notebooks/pre-processing/get_data_npz.ipynb): Para facilitar a treinamento e diminuir o custo computacional durante o treinamento, os dados foram convertidos de NIfTI para npz. Uma vez os dados corretos e alinhados com a m√°scara √© mais vantajoso computacionalmente converter para um formato mais leve. Neste caso, o npz n√£o armazena a informa√ß√£o do cabe√ßalho da imagem e isso diminui o custo computacional e tempo de execu√ß√£o ao carregar os dados durante o treinamento. Para cada experimento (3D) os dados foram salvos em npz (imagem e m√°scara no mesmo arquivo). Por exemplo, ap√≥s a realiza√ß√£o do pr√©-processamento de normaliza√ß√£o, os dados eram salvos em npz.

### Utiliza√ß√£o e divis√£o dos conjuntos de dados 
Para o treinamento das vers√µes arquitetura (2D e 3D), os conjuntos de dados LBPA40, CC359 e NFBS foram usados simultaneamente durante o treinamento do modelo em todos os experimentos. Os dados foram ent√£o dividos (incluidos esses 3 conjuntos de dados) em treinamento (392 sujeitos: 87 do NFBS, 277 do CC359 e 28 do LBPA40) e valida√ß√£o (103 sujeitos: 25 do NFBS, 70 do CC359 e 8 do LBPA40). A avalia√ß√£o do modelo foi feita no conjunto de teste final (xx sujeitos) (VERIFICAR SE ISSO VAI SE MANTER PARA O 2D)

### Treinamento da arquiterura 2D

### Treinamento da arquiterura 3D
O treinamento do modelo 3D foi realizado ao utilizar o volume de entrada para obter patch 3D que foi usado como canal de entrada da U-Net 3D. A rede realiza o treinamento e retorna como sa√≠da a segmenta√ß√£o do c√©rebro.  

![Workflow 3D: treinamento da U-Net 3D usando patch obtido aleatoriamente do volume de entrada (I) e predi√ß√£o usando patches 3D no volume de entrada (II).](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/assets/Workflow_3D.png)

#### Treinamento e Avalia√ß√£o do Modelo 3D

Por ser uma arquitetura totalmente convolucional, o tamanho da imagem para o treinamento da U-Net n√£o precisa ser o mesmo da avalia√ß√£o. Sendo assim, o treinamento do modelo 3D foi feito usando patch 3D de tamanho 102 √ó 102 √ó 102 nos canais de entrada (Fig x). Para cada volume (amostra) √© escolhido um patch de forma aleat√≥ria, como √© apenas um de cada imagem, isso introduz variabilidade a cada amostra passada para a rede, mas n√£o √© necessariamente um aumento de dados. 

Com o modelo treinado, a segmenta√ß√£o volum√©trica do c√©rebro de uma nova amostra foi feita ao passar uma imagem completa para o modelo (Fig. x-II). Para isso, foi usado um m√©todo de infer√™ncia de janela deslizante, inspirado na implementa√ß√£o da [nnU-Net](https://www.nature.com/articles/s41592-020-01008-z) e usando uma implementa√ß√£o do [Monai](https://link.springer.com/chapter/10.1007/978-3-031-12053-4_58). Esse m√©todo reconstr√≥i a segmenta√ß√£o completa do volume de entrada usando patches com pondera√ß√£o gaussiana para predi√ß√µes e uma janela 3D de 10%.

# Ferramentas

Dentre as ferramentas utilizadas est√£o: nibabel, matplotlib, simpleITK, ITKSnap e framework nn-Unet.

# Workflow

> Fazer na pr√≥xima etapa.

## Experimentos e Resultados preliminares
### nnU-Net
O framework realiza o pr√©-processamento dos dados usando o comando "nnUNetv2_plan_and_preprocess -d DATASET_ID --verify_dataset_integrity" e para treinamento o comando "nnUNetv2_train DATASET_NAME_OR_ID UNET_CONFIGURATION FOLD --val --npz". Como o objetivo da execu√ß√£o da nnU-Net √© apenas obter algumas ideias de pr√©-processamento deste dataset, n√£o iremos detalhar este framework aqui, para mais informa√ß√µes, consulte o tutorial da [nnU-Net](https://github.com/MIC-DKFZ/nnUNet/tree/master).

> * Os dados foram organizados em pastas para cada sujeito. Em seguida eles foram separados em trainamento (80%), valida√ß√£o (10%) e teste (10%). O primeiro experimento foi feito sem pr√©-processamento dos dados.

> * O experimento do treinamento realizado est√° descrito no arquivo unet_sem_preproc.ipynb.

> * Ap√≥s o treinamento da nn-Unet, obtiveram-se os seguintes resultados e pr√©-processamentos sugeridos pelo framework.

### Avalia√ß√£o da U-Net 3D
> O treinamento do modelo inclui o uso de [Dice Loss](https://link.springer.com/chapter/10.1007/978-3-319-67558-9_28) como fun√ß√£o de perda e [otimizador Adam](https://arxiv.org/abs/1412.6980). O tamanho do batch foi o mesmo sugerido pelo framework nnU-Net, 2. O tamanho de patch n√£o foi o mesmo sugerido pala nnU-Net, isso porque n√£o havia GPU que coubesse o tamanho de patch sugerido, logo foi necess√°rio diminuir o tamanho de patch para (102 x 102 x102)

# Pr√≥ximos passos

Trainar uma U-Net 3D a partir de alguns pr√©-processamentos fornecidos pela nn-Unet.

## Refer√™ncias

Lucena, O., Souza, R., Rittner, L., Frayne, R., & Lotufo, R. (2018, April). Silver standard masks for data augmentation applied to deep-learning-based skull-stripping. In 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018) (pp. 1114-1117). IEEE.

Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.

Carmo, D., Silva, B., Yasuda, C., Rittner, L., & Lotufo, R. (2021). Hippocampus segmentation on epilepsy and Alzheimer's disease studies with multiple convolutional neural networks. Heliyon, 7(2).
