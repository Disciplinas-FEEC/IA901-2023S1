# `Segmenta√ß√£o do c√©rebro usando imagens T1`
# `Brain Segmentation on T1 images`

## Apresenta√ß√£o

O presente projeto foi originado no contexto das atividades da disciplina de p√≥s-gradua√ß√£o *IA901 - Processamento de Imagens e Reconhecimento de Padr√µes*, oferecida no primeiro semestre de 2023, na Unicamp, sob supervis√£o da Profa. Dra. Leticia Rittner, do Departamento de Engenharia de Computa√ß√£o e Automa√ß√£o (DCA) da Faculdade de Engenharia El√©trica e de Computa√ß√£o (FEEC).

|Nome  | RA | Curso|
|--|--|--|
| Jimi Togni           | 226359   | Doutorado em Engenharia El√©trica |
| Joany Rodrigues      | 264440   | Mestrado em Engenharia El√©trica  |
| Victor Praxedes Rael | 240242   | Mestrado em Engenharia El√©trica  |

## Descri√ß√£o do Projeto

Muitos desafios na √°rea de imagem m√©dica exigem como pr√©-processamento a segmenta√ß√£o do c√©rebro, por exemplo, a realiza√ß√£o de registro e segmenta√ß√£o de estruturas cerebrais. Muitas propostas tem surgindo para solucionar este problema, o que j√° tem boas propostas na literatura, por exemplo, o trabalho por [LUCENA, Oeslle et al.](https://ieeexplore.ieee.org/abstract/document/8363766?casa_token=Y9VwrDbJQJ8AAAAA:7MsKQIPK9IAl2PD8zla2eRkO2jNtqUilIMtqGjEBGlRb_P9SNNJkXwgJR91otfmY_wGeJSfhGJg). 

Tem surgido propostas na literatura mostrando que ao aplicar t√©cnicas de pr√©-processamento e aumento de dados pode ser mais vantajoso do que apenas usar t√©cnicas de √∫ltima gera√ß√£o. Por exemplo, a implementa√ß√£o do framework [nnU-Net](https://www.nature.com/articles/s41592-020-01008-z), que busca o melhor pr√©-processamento de um conjunto de dados e hiperpar√¢metros da rede para este conjunto de dados, automaticamente. O objetivo deste framework √© usar a arquitetura de uma CNN simples [U-Net](https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28) para buscar de maneira aut√¥noma o melhor modelo de segmenta√ß√£o de objetos de acordo com as caracter√≠sticas dos dados. Logo, este framework foi executado com o objetivo de adquirir os pr√©-processamentos dos conjuntos de dados usados neste trabalho e usar como ponto de partida para o treinamento 3D deste projeto.

Logo, o objetivo deste projeto √© usar partes de um conjunto de dados de segmenta√ß√£o do c√©rebro para executar um experimento na nnU-Net e obter suas sugest√µes de p≈ïe-processamento de dados e par√¢metros da rede para estud√°-los e definir os mais intuitiv√©is e fact√≠veis, para em seguida, desenvolver um m√©todo de segmenta√ß√£o do c√©rebro usando uma vers√£o da arquitetura U-Net. Este estudo inclu√≠ averiguar quais dos pr√©-processamentos dos dados s√£o vi√°veis para a melhoria de um modelo de segmenta√ß√£o do c√©rebro.

## Bases de Dados e Evolu√ß√£o

Base de Dados | Endere√ßo na Web | Resumo descritivo
------------- | --------------- | -----------------
LBPA40 | [link de acesso](https://www.loni.usc.edu/research/atlas_downloads) | este conjunto de dados √© p√∫blico e cont√©m dados de 40 sujeitos. Dentre outros arquivos, este conjunto de dados cont√©m as imagens ponderadas em T1 e segmenta√ß√µes manuais do c√©rebro tamb√©m em T1. Esse conjunto de dados foi fornecido por um membro do grupo MICLab. Os dados originais est√£o no formato mri.img.gz, por√©m os dados fornecidos para este estudo j√° se encontrava no formato nifti. A convers√£o de img.gz para NIfTI foi feita usando o software [ITKSnap](http://www.itksnap.org/pmwiki/pmwiki.php?n=Documentation.TutorialSectionInstallation). Para a organiza√ß√£o desses dados, foi feito a separa√ß√£o apenas dos arquivos que foram usados neste trabalho (imagens e segmenta√ß√£o do c√©rebro); em seguida renomeamos estes arquivos para brainmask_T1w (segmenta√ß√£o do c√©rebro) e brain_T1w (imagem do c√©rebro) e ent√£o realizamos a divis√£o deste dataset em treinamento (70%), valida√ß√£o (20%) e teste (10%). Detalhes para esta organiza√ß√£o est√£o no notebook [organiza√ß√£o dos dados LBPA40](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/notebooks/data_organization/LBPA40_dataset_organization.ipynb). 
CC359 | [link de acesso](https://portal.conp.ca/dataset?id=projects/calgary-campinas) | este √© um conjunto de dados de resson√¢ncia magn√©tica cerebral desenvolvido por pesquisadores da universidade de Calgary e Unicamp (MICLab). √â composto por imagens de RM do c√©rebro ponderadas em T1 e m√°scaras de segmenta√ß√£o do c√©rebro tamb√©m em T1. Cont√©m 359 sujeitos todos com segmenta√ß√£o padr√£o-prata gerada a partir de um consenso entre segmenta√ß√µes obtidas por pelo menos 3 ferramentas (STAPLE). Apenas 12 sujeitos desses conjunto de dados cont√©m m√°scaras manuais geradas por um especialista. Este conjunto de dados foi adquirido no formato NIfTI e em dois diret√≥rios: um onde continham todas as imagens de todos os sujeito (original) e outro com todas as m√°scaras de todos os sujeitos (staple). Novamente, este conjunto de dados foi fornecido por um membro do grupo MICLab. A partir dos dados fornecidos n√£o foi poss√≠vel identificar os dados que continham segmenta√ß√£o manual. Para isso, foi preciso baixar os dados com anota√ß√£o manual do site e identificar os sujeitos com anota√ß√µes manuais, para separ√°-los manualmente e utiliz√°-los para teste final do modelo. Tamb√©m, foi preciso separar os dados de cada sujeito em pastas (uma pasta para cada sujeito) com as imagens e as m√°scaras. Em seguida as imagens foram renomeadas para brain_T1w e as segmenta√ß√µes para brainmask_T1w. Por fim foi feito a divis√£o dos dados sem anota√ß√£o manual (347 sujeitos) em treinamento (80%) e valida√ß√£o (20%). Detalhes da organiza√ß√£o desse conjunto de dados est√£o no notebook [organiza√ß√£o dos dados CC359](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/notebooks/data_organization/CC359_dataset_organization.ipynb).
NFBS | [link de acesso](http://preprocessed-connectomes-project.org/NFB_skullstripped/) | √© um dataset com 125 resson√¢ncias magn√©ticas anat√¥micas ponderadas em T1 que tem anota√ß√µes manuais do c√©rebro. Este conjunto de dados fornece 3 arquivos para cada sujeito: Structural T1-weighted anonymized image, Skull-stripped image, Brain mask. (FALTA DESCREVER COMO FOI FEITA A ORGANIZ√á√ÉO DESTE CONJUNTO DE DADOS)

Detatalhes importantes sobre os conjuntos de dados e sua organiza√ß√£o:
* Todos os conjuntos de dados originais est√£o no formato NIfTI.
* A organiza√ß√£o dos dados foi feita separadamente para cada conjunto de dados. Isso porque os conjuntos de dados eram muito diferentes e nos perdemos ao tentar implementar um √∫nico c√≥digo para organizar e separar em treinamento valida√ß√£o e teste automaticamente. Al√©m disso, alguns passos simples foram feitos manualmente como, criar pastas para cada conjunto de dados ou separar os dados com anota√ß√µes manuais do conjunto de dados CC359.
* Para o treinamento da nn-Unet n√£o foram usados todos os conjuntos de dados, apenas alguns dados do CC359, LBPA40 e NFBS, pois ainda est√°vamos muito perdidos nessa organiza√ß√£o. A quantidade de dados usados inclu√≠do os tr√™s conjuntos foi de 240 sujeitos e a divis√£o do conjunto de dados em treinamento e valida√ß√£o √© feito automaticamente pelo framework. 29 sujeitos desses 3 conjuntos de dados foram reservados para teste final do experimento do framework. Ainda, foi preciso organizar os dados da maneira que o framework exige, consulte o [tutorial da nnU-Net](https://github.com/MIC-DKFZ/nnUNet/tree/master). Em seguida, as anota√ß√µes foram binarizadas usando limiariza√ß√£o de 0.5, uma vez que os dados adquiridos estavam com as m√°scaras de tipo float (entre 0 e 1) nas bordas e este framework n√£o permite m√°scaras com labels que n√£o cont√™m valores inteiros. A implementa√ß√£o para isso est√° no notebook [organizar de dados para executar a nnU-Net](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/notebooks/data_organization/organizar_dados_nnUNet.ipynb).
* Essa divis√£o dos conjuntos de dados foi usada apenas no modelo 3D.

## Metodologia
### Arquitetura U-Net
Este trabalho utilizou a arquitetura [U-Net](https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28), uma rede neural convolucional bastante utilizada para segmenta√ß√£o de imagens m√©dicas. Utilizamos as vers√µes 2D e 3D da [U-Net modificada](https://link.springer.com/chapter/10.1007/978-3-030-72084-1_38), conforme implementado por Carmo et al. (2020). 

![U-Net modificada](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/assets/Unet-IA901A.png)*Figura 01 - U-Net modificada: a resolu√ß√£o espacial √© reduzida pela segunda convolu√ß√£o de cada n√≠vel do codificador; os blocos verde se referem as caracter√≠sticas filtradas pela opera√ß√£o de self attention; cada n√≠vel do codificador e decodificador (blocos de duas convolu√ß√µes) possui conex√£o residual realizando a conex√£o da entrada da primeira convolu√ß√£o √† sa√≠da da segunda convolu√ß√£o (seta em laranja)*

Muda√ßas da U-Net modificada em rela√ß√£o a original inclui: a utiliza√ß√£o de convolu√ß√µes stride para a redu√ß√£o da resolu√ß√£o espacial em vez de opera√ß√µes de agrega√ß√£o; adi√ß√£o de [conex√£o residual](https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html) propagando a entrada √† sa√≠da de cada n√≠vel do codificador (utilizando soma e uma convolu√ß√£o com kernel de 1 √ó 1 (seta laranja) realizando adapta√ß√£o de canal e resolu√ß√£o espacial e adi√ß√£o de uma opera√ß√£o [self attention](http://proceedings.mlr.press/v102/gorriz19a.html) para filtrar as caracter√≠sticas produzidas em cada n√≠vel do codificador.

Modifica√ß√µes entre as vers√µes 2D e 3D inclui: o n√∫mero de canais de entrada para a vers√£o 3D √© reduzido devido ao aumento da dimensionalidade da variante 3D, uma vez que cada volume √© considerado um canal, enquanto para a vers√£o 2D cada fatia de um volume √© considerado um canal; utiliza√ß√£o de normaliza√ß√£o de inst√¢ncia para a vers√£o 3D, comumente usada em redes convolucionais 3D com batch pequeno e a normaliza√ß√£o em lote para a vers√£o 2D, pois o tamanho do batch √© consideravelmente maior e costuma funcionar bem neste caso quando utiliza convolu√ß√µes 2D.

### Pr√©-Processamento de dados
#### nnU-Net 
Os dados foram executados no framework nnU-Net apenas para obtermos sugest√µes de pr√©-processamento dos dodos e par√¢metros da rede. Para a execus√£o dos dados na nnU-Net, foi necess√°rio organizar os dados da forma que esta exige. A implementa√ß√£o usada para organiza√ß√£o no conjunto de dados usados neste trabalho pode ser encontrado no notebook [organizar de dados para executar a nnU-Net](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/notebooks/data_organization/organizar_dados_nnUNet.ipynb), para mais informa√ß√µes acesse o tutorial do framework. 

Ao executarmos os dados na nnU-Unet, esta forneceu um problema nas segmenta√ß√µes anotadas, uma vez que as essas n√£o era bin√°rias (continham valores entre 0 e 1) e este framework n√£o aceita labels que n√£o sejam num√©ros inteiros. Isso foi importante para sabermos que as segmenta√ß√µes dos dados n√£o estavam binarizadas. Isso foi corrigido para execu√ß√£o da nnU-Net usando o c√≥digo presente tamb√©m no notebook [organizar de dados para executar a nnUNet](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/notebooks/data_organization/organizar_dados_nnUNet.ipynb).

Ap√≥s a execu√ß√£o da nnU-Net, foi obtido uma [lista de pr√©-processamento](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/assets/debug.json) do treinamento 3D e 2D realizado pelo framework. A partir dessa lista, consideramos os seguintes pr√©-processamentos para o treinamento das duas vers√µes da arquitetura U-Net (2D e 3D):

#### Defini√ß√£o de Pr√©-processamentos
* [Redimensionamento de voxel](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/notebooks/pre-processing/voxel_interpolation.ipynb) (spacing): redimensionamento de voxel √© interpolar o voxel para mudar seu tamanho, o que influencia diretamente na resolu√ß√£o da imagem. Isso modifica significativamente os dados chegando a introduzir ru√≠do a partir da interpola√ß√£o. No entando, al√©m de ter sido sugerido pelo framewark, este trabalho usa 4 conjunto de dados diferentes e para manter os voxels de todos os dados padronizados foi feito a interpola√ß√£o de voxel, mantendo todos os volumes de treinamento e valida√ß√£o isom√©tricos com tamanho de voxel igual a 1. Observe que a sujest√£o da nnU-Net foi de [1.0, 0.9999008178710938, 1.0], mas foi usado [1.0, 1.0, 1.0] para deixar os dados isom√©tricos. A tabela abaixo resume o tamanho de voxel e resolu√ß√£o dados de cada conjunto de dados antes e ap√≥s a interpola√ß√£o de voxel.

|Aquisi√ß√£o| Tam. Vox. original (ùëöùëö^3) | Tam. Vox. Iso (ùëöùëö^3) | resolu√ß√£o original | resolu√ß√£o c/ Interpola√ß√£o de Voxel |
|---------|---------------------------|-----------------------|--------------------|-----------------------|
| CC359   | 1 x 1 x 1                 | 1 x 1 x 1             | 171 x 256 x 256    | 171 x 256 x 256 |
| LBPA40  | 0.8594 x 1.5 x 0.8594     | 1 x 1 x 1             | 256 x 124 x 256    | 220 x 186 x 120 |
| NFBS    | 1 x 1 x 0.9999            | 1 x 1 x 1             |  256 x 256 x 192   | 256 x 256 x 192 |

* [Normaliza√ß√£o](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/notebooks/pre-processing/data_normalization.ipynb): a normaliza√ß√£o sugerida pelo framework foi a Z-Score Normalization 'ZScoreNormalization'. Essa √© uma t√©cnica utilizada para transformar os valores de uma vari√°vel para que tenham m√©dia zero e desvio padr√£o igual a 1. Bastante utilizada quando se tem vari√°veis que t√™m escalas diferente, deixando as vari√°veis em uma escala compat√≠vel ou compar√°vel. Em MRIs, para a realiza√ß√£o dessa normaliza√ß√£o a imagem √© subtra√≠da de sua m√©dia e essa opera√ß√£o √© dividida pelo desvio padr√£o da imagem: 

$$ X_{nor} =  (X - \mu) / (\sigma)$$

Onde X √© a matriz (volume); $\mu$ √© a m√©dia da matriz; e $\sigma$ √© o desvio padr√£o da matriz. Essa normaliza√ß√£o resulta em m√©dia igual a 0 e desvio padr√£o igual a 1.

* [Convers√£o para o npz](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/notebooks/pre-processing/get_data_npz.ipynb): Para facilitar a treinamento e diminuir o custo computacional durante o treinamento, os dados foram convertidos de NIfTI para npz. Uma vez os dados corretos e alinhados com a m√°scara √© mais vantajoso computacionalmente converter para um formato mais leve. Neste caso, o npz n√£o armazena a informa√ß√£o do cabe√ßalho da imagem e isso diminui o custo computacional e tempo de execu√ß√£o ao carregar os dados durante o treinamento. Para cada experimento (3D) os dados foram salvos em npz (imagem e m√°scara no mesmo arquivo). Por exemplo, ap√≥s a realiza√ß√£o do pr√©-processamento de normaliza√ß√£o, os dados eram salvos em npz.

### Utiliza√ß√£o e divis√£o dos conjuntos de dados 
Para o treinamento da vers√£o da arquitetura 3D, os conjuntos de dados LBPA40, CC359 e NFBS foram usados simultaneamente durante o treinamento do modelo em todos os experimentos. Os dados foram ent√£o dividos (incluidos esses 3 conjuntos de dados) em treinamento (392 sujeitos: 87 do NFBS, 277 do CC359 e 28 do LBPA40) e valida√ß√£o (103 sujeitos: 25 do NFBS, 70 do CC359 e 8 do LBPA40). A avalia√ß√£o do modelo foi feita no conjunto de teste final (xx sujeitos) (VERIFICAR SE ISSO VAI SE MANTER PARA O 2D)

### M√©tricas de Avalia√ß√£o
As m√©tricas de avalia√ß√£o utilizadas foram:
* [Coeficiente Dice (ou DSC, do ingl√™s Dice Similarity Coefficient)](https://www.jstor.org/stable/1932409?casa_token=RFaYUTaEtkUAAAAA%3ANV4GvJGgLFTE922Oa9Paw7Jar5HM07VQYC3_IQf86hbOuUQv2mAjpYDzCBZ_X4BFo7azcJ_uu3mk0tTeY-qi3HufoQaE2t_0SMEPbDAhcHjs-9TBLz3D): bastante utilizada para avalia√ß√£o de segmenta√ß√µes (DICE, 1945), compara duas segmenta√ß√µes diferentes, fornecendo a semelhan√ßa entre elas e. Esta √© dada por:

$$ Dice =  2VP / FP + FN + 2VP$$

* [Similaridade de volume (SV)](https://ieeexplore.ieee.org/abstract/document/7053955): complementar ao Dice, mede a similaridade de volume entre duas segmenta√ß√µes (dist√¢ncia volum√©trica). Indica a diferen√ßa absoluta de volume dividida pela soma dos volumes comparados, definida por:

$$ SV = 1 - \frac{\left| FN - FP \right|}{2VP + FP + FN}$$

$VP$ s√£o valores classificados corretamente como positivos, $FP$ s√£o valores classificados erroneamente como positivos e $FN$ s√£o valores classificados erroneamente como negativos.

* Dist√¢ncia m√©dia de Hausdorff (AVD, do ingl√™s average Haousdorff distance): utilizadas como medidas de dissimilaridade, calcula a dist√¢ncia m√©dia euclidiana entre os contornos calculados sobre todos os pontos, definida por:

$$ AVD = max(max_{s\in{S}}\left| d_s \right| . max_{r\in{R}}\left| d_r \right|)$$

$d$ √© a dist√¢ncia m√©dia controlada pela m√©trica $AVD$, $AVD$ √© a segmenta√ß√£o de refer√™ncia (padr√£o-ouro), $S$ √© a segmenta√ß√£o obtida pelo m√©todo, $r$ e $s$ s√£o os pontos contidos nos contornos de $R$ e $S$, respectivamente, e $d_s$ e $d_r$ s√£o as dist√¢ncias m√©dias entre os pontos $s$ e $r$ aos pontos de contorno de $R$ e $S$ mais pr√≥ximos.

### Treinamento da arquiterura 2D

### Treinamento da arquiterura 3D
O treinamento do modelo 3D foi realizado ao utilizar o volume de entrada para obter patch 3D que foi usado como canal de entrada da U-Net 3D. A rede realiza o treinamento e retorna como sa√≠da a segmenta√ß√£o do c√©rebro.  

![Workflow 3D](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/assets/Workflow_3D.png)
*Figura 02 - Workflow 3D: treinamento da U-Net 3D usando patch obtido aleatoriamente do volume de entrada (I) e predi√ß√£o usando patches 3D no volume de entrada (II).*

#### Treinamento e Avalia√ß√£o do Modelo 3D

Por ser uma arquitetura totalmente convolucional, o tamanho da imagem para o treinamento da U-Net n√£o precisa ser o mesmo da avalia√ß√£o. Sendo assim, o treinamento do modelo 3D foi feito usando patch 3D de tamanho 102 √ó 102 √ó 102 nos canais de entrada (Fig x). Para cada volume (amostra) √© escolhido um patch de forma aleat√≥ria, como √© apenas um de cada imagem, isso introduz variabilidade a cada amostra passada para a rede, mas n√£o √© necessariamente um aumento de dados. 

Com o modelo treinado, a segmenta√ß√£o volum√©trica do c√©rebro de uma nova amostra foi feita ao passar uma imagem completa para o modelo (Fig. x-II). Para isso, foi usado um m√©todo de infer√™ncia de janela deslizante, inspirado na implementa√ß√£o da [nnU-Net](https://www.nature.com/articles/s41592-020-01008-z) e usando uma implementa√ß√£o do [Monai](https://link.springer.com/chapter/10.1007/978-3-031-12053-4_58). Esse m√©todo reconstr√≥i a segmenta√ß√£o completa do volume de entrada usando patches com pondera√ß√£o gaussiana para predi√ß√µes e uma janela 3D de 10%.

#### Aumento de dados
Para a abordagem 3D, foram testadas apenas as t√©cnicas de RandomAffine e a RandomBlur implementadas na biblioteca [TorchIO](https://torchio.readthedocs.io/transforms/augmentation.html).

1. RandomAffine: √© uma transforma√ß√£o geom√©trica aleat√≥ria que pode ser aplicada na imagens e permite a combina√ß√£o aleat√≥ria de rota√ß√£o, transla√ß√£o, redimensionamento, cisalhamento e reflex√£o em uma imagem. √â comumente usada para criar varia√ß√µes sint√©ticas nos dados de treinamento e melhorar a robustez e generaliza√ß√£o de modelos de aprendizado de m√°quina. Neste trabalho foram aplicados para essa t√©cnica o fator escala (scales) de (0.9, 1.2) e graus (degrees) de 90.  Graus √© um intervalo de √¢ngulos de rota√ß√£o poss√≠veis, em que cada √¢ngulo √© escolhido aleatoriamente dentro desse intervalo, enquanto a escala √© um fator de escala de m√≠nimo e m√°ximo, em que √© escolhido aleatoriamente dentro desse intervalo. 

### Ferramentas

As principais ferramentas utilizadas para o pr√©-processamento dos dados e treinamento do modelo foram:
* [NiBabel](https://nipy.org/nibabel/): Uma biblioteca para vizualiza√ß√£o e pr√©-processamento de dados no formato n√≠fiti. Neste trabalho esta biblioteca foi usada principalmente para leitura das imagens, uma vez que permite acessar informa√ß√µes do cabe√ßalho das imagens, como matriz affine (as vezes necess√°ria para salvar corretamente resultados de um pr√©-processamenta). Tamb√©m permite obter as imagens no fromato de uma matriz ou numpy para realiza√ß√£o dos pr√©-processamentos.

* [Matplotlib](https://matplotlib.org/stable/index.html): bastante √∫til para vizualiza√ß√£o dos resultados qualitativos, permitindo se necess√°ria a inspe√ß√£o de cada passo realizado.

* [simpleITK](https://simpleitk.org/doxygen/v2_1/html/): √© uma biblioteca com funcionalidade semelhante √† nibabel. Esta biblioteca tem sido recorrentemente utilizada por pesquisadores na √°rea da imagem m√©dica, uma vez que permite e simplifica algumas manipula√ß√µes desses dados, por exemplo, quando o pr√©-processamento exige a modifica√ß√£o da matriz affine. Garantir resultados coerentes com a biblioteca nibabel quando se deseja modificar a affine dos dados √© relativamente mais complexo do que usar a simpleITK. Neste trabalho, ela foi usada para realizar o pr√©-processamento de [interpola√ß√£o de voxel](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/notebooks/pre-processing/voxel_interpolation.ipynb).   

* [ITKSnap](http://www.itksnap.org/pmwiki/pmwiki.php?n=Documentation.TutorialSectionInstallation): √© uma ferramenta utilizada para inspe√ß√£o e visualiza√ß√£o de dados volum√©tricos ou 2D em imagens m√©dicas. Ela foi utiliza para este fim neste trabalho. 

* [nnU-net](https://www.nature.com/articles/s41592-020-01008-z): √© um framework que realiza automaticamente pr√©processamento de dados e trainamento de modelos de segmenta√ß√£o de imagens. Al√©m disso, fornece os pr√©-processamentos que melhor se adequa a conjuntos de dados especificos, assim como par√¢metros da arquitetura. Neste trabalho, ele foi usado para obter sugest√µes do pr√©-processamento de dados e hiperpar√¢metros da rede, que alguns foram escolhidos para serem usados como ponto de partida neste trabalho.

* [PyTorch Lightning](https://lightning.ai/docs/pytorch/stable/): √© um framework relativamente leve para treinamento de modelos de aprendizado profundo, que oferece uma abstra√ß√£o de alto n√≠vel sobre o PyTorch. Ele simplifica e organiza o c√≥digo, facilitando a cria√ß√£o, o treinamento e o teste de modelos de aprendizado profundo de forma mais estruturada. Al√©m disso, tem f√°cil conex√£o com o Neptune.

* [Neptune](https://neptune.ai/): √© uma plataforma de colabora√ß√£o para experimentos de aprendizado de m√°quina. Ele oferece recursos avan√ßados para rastrear, visualizar e compartilhar experimentos, bem como para monitorar e otimizar modelos de aprendizado de m√°quina. Com uma interface intuitiva e simples, permite acompanhar todas as etapas de um projeto, desde a coleta de dados at√© a implanta√ß√£o do modelo. Neste trabalho, foi utilizado apenas para monitoramento do modelo 3D.

* [TorchIO](https://torchio.readthedocs.io/transforms/augmentation.html): uma biblioteca de processamento de imagens baseada no PyTorch, que permite transforma√ß√µes e utilidades para o pr√©-processamento de dados m√©dicos. Fornece um conjunto de transforma√ß√µes flex√≠veis para manipula√ß√£o e aumenta√ß√£o de dados de imagem, como rota√ß√£o, transla√ß√£o, redimensionamento, normaliza√ß√£o, entre outras. O TorchIO √© frequentemente usado em imagem 3D, por oferecer simplicidade na implementa√ß√£o de manipula√ß√£o de volumes, no entanto, n√£o √© limitado apenas a dados 3D e pode ser usado para processar dados 2D e 1D, desde que haja ajuste as transforma√ß√µes e opera√ß√µes de acordo com a natureza dos seus dados.

* Al√©m dessas ferramentas, outras foram usadas para monipula√ß√£o dos dados, como: [NumPy](https://numpy.org/doc/). (COLOCAR OUTRAS FERRAMENTAS). 

> Fazer na pr√≥xima etapa.

## Experimentos e Resultados
### nnU-Net
O framework realiza o pr√©-processamento dos dados usando o comando "nnUNetv2_plan_and_preprocess -d DATASET_ID --verify_dataset_integrity" e para treinamento o comando "nnUNetv2_train DATASET_NAME_OR_ID UNET_CONFIGURATION FOLD --val --npz". Como o objetivo da execu√ß√£o da nnU-Net √© apenas obter algumas ideias de pr√©-processamento deste dataset, este n√£o ser√° detalhado aqui, para mais informa√ß√µes, consulte o tutorial da [nnU-Net](https://github.com/MIC-DKFZ/nnUNet/tree/master).

Apenas o modelo 3D da nnU-Net foi executado e o resultado obtido por este foi um valor de Dice m√©dio de 0,9898 no conjunto de valida√ß√£o. Detalhes sobre este resultados pode ser encontrado no [arquivo summary](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/assets/summary.json) e [gr√°fico](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/assets/progress.png) fornecidos pelo framework. 

### Avalia√ß√£o da U-Net 2D

### Avalia√ß√£o da U-Net 3D
Os experimentos desta se√ß√£o foram realizados em uma GPU Titan X. Experimentos foram realizados para testar a aplica√ß√£o de pr√©-processamento de dados (redimensioanmento de voxel e normaliza√ß√£o) e definir aumento de dados e os principais hiperpar√¢metros, como a learning rate e n√∫mero de √©pocas. Desde o in√≠cio, foram mantidos fixos o uso do [otimizador Adam](https://arxiv.org/abs/1412.6980) com [Dice Loss](https://link.springer.com/chapter/10.1007/978-3-319-67558-9_28), o m√©todo de patch RandomCrop com seu tamanhos de (102, 102, 102) e o tamanho do batch de 2. Esses par√¢metros fixos foram usados de acordo com os sugeridos pela nnU-Net, com exce√ß√£o do otimizados e da fun√ß√£o de perda. Tamb√©m o tamanho de patch n√£o foi o mesmo sugerido pela nnU-Net, pois a GPU usada para a execu√ß√£o do treinamento, n√£o permitiu o tamanho de patch de (128, 128, 128).

Os objetivos desses experimentos foram (de acordo com o sugerido pela nnU-Net):
1. Verificar quais pr√©-processamentos s√£o relevantes para melhorar o desempenho do modelo;
2. Verificar quais aumento de dados ajudam a obter um modelo mais robusto;
3. Verificar se h√° ganho significativo ao mudar os hiperpar√¢metros taxa de aprendizado e n√∫mero de √©poca.

A execu√ß√£o dos experimentos usando a U-Net 3D, objetivou avaliar a aplica√ß√£o dos pr√©-processamento: redimensionamento de voxel, normaliza√ß√£o e padroniza√ß√£o das labels das anota√ß√µes fornecidas nos conjuntos de dados. Tamb√©m a avalia√ß√£o da t√©cnica de aumento de dados RandomAffine (Tab. 2). 


Tabela 1: Dice m√©dio no conjunto de valida√ß√£o para os experimentos realizados usando a U-Net 3D: dados sem nenhum processamento (Experimento 1); ao realizar a padroniza√ß√£o das labels de entre os 3 datasets (Experimento 2); Depois de padronizar as labels, foi feita a interpola√ß√£o de voxel nos dados (Experimento 3); em seguida os dados foram normalizados (Experimento 4); por fim foi testado a t√©cinca de Random Affine (Experimento 5).
|Experimento  | N¬∞ de √©pocas (√©poca) | perda |modelo| p√≥s-processada|
|-------------|-----------------|--------------|-------|------------|
| 1 |500 (459)             | -0.05 | 0.6643     | 0.8309
|2 | 100 (68)             | 0.04  | 0.7752     | 0.8239
|3 |100 (90)              | 0.03  | 0.8953     | 0.9044|
| 4  |100 (55)              | 0.03  | 0.9637     | 0.97307 |
|5   |100 (55)              | 0.03  | 0.9357     | 0.9596 |

Note que o pr√©-processamento √© sequencial, sendo que a interpola√ß√£o do voxel foi aplica nos dados com as labels padronizadas. Foi observado que realizar o pr√©-processamento nos dados ajuda no desempenho do modelo, principalmente a normaliza√ß√£o dos dados e a interpola√ß√£o de voxel. 

As figuras abaixo mostram as curvas de perda do treinamento e da valida√ß√£o. O experimento 4 e convergiram melhor se comparados aos demais experimentos, no entanto, o experimento 4 convergiu melhor, apresentando melhores resultados na avalia√ß√£o feita no conjunto de valida√ß√£o. Este foi definido para a an√°lise subsequente. 

![Train_loss](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/assets/training_loss_epoch.png)*Figura 03 - Curva de aprendizado durante o treinamento (fun√ß√£o de perda para o treinamento): experimetos 2 (rosa), 3 (amarelo), 4 (vinho); e 5 (azul)*

![Val_loss](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/assets/training_val_loss.png)*Figura 04 - Curva de aprendizado durante o treinamento (fun√ß√£o de perda para a valida√ß√£o: experimetos 2 (rosa), 3 (amarelo), 4 (vinho); e 5 (azul)*

A avalia√ß√£o no conjunto de teste foi feita apenas no melhor modelo 3D (experimento 4). Foi poss√≠vel fazer um estudo ao realizar a predi√ß√£o usando todos os conjuntos de dados do conjunto de teste simultaneamente ou separadamente.


Tabela 1 : Resultados das m√©tricas para o melhor modelo 3D (conjunto de teste): m√©dia e desvio padr√£o.
|Conjunto de dados     |Dice             | AVD                  | SV    |
|----------------------|-----------------|----------------------|-------|
|todos                 | $0.9629\pm0.0055$| $0.0673\pm0.0242$   | $0.9849\pm0.0080$   |
| IBSR                |$0.9737\pm0.0032$|$0.0445\pm0.0259$     | $0.9867\pm0.0100$|
| CC359                 |$0.9671\pm0.0031$|$0.0593\pm0.0116$ |$0.9880\pm0.0082$ | 
| LBPA40              | $0.9671\pm0.0031$ |$0.0593\pm0.0116$ | $0.9880\pm0.0082$|

Os resultados foram satisfat√≥rios, uma vez que o dice m√©dio se manteve pr√≥ximo ao que foi apresentado no conjunto de valida√ß√£o e treinamento. Al√©m disso, n√£o houve divergencia entre os conjuntos de dados, pois os resultados s√£o bastante semelhantes inclusive com os resultados de todos os conjuntos de dados juntos.

Os resultados qualitativos (Figura 5) confirmam a boa qualidade das segmenta√ß√µes obtida pelo modelo. O pior resultado aparenta ser no conjunto de dados LBPA40.

![Res_qual](https://github.com/jimitogni/IA901-2023S1/blob/vers%C3%B5es_unet/projetos/Brain_segmentation/assets/resul_qual_3D.png)*Figura 05 - Resultados qualitativos usando o melhor Dice obtido em cada conjunto de dados. Renderiza√ß√£o 3D da sa√≠da do modelo (sup.) e sobreposi√ß√£o das anota√ß√£o manual e a sa√≠da do modelo em fatias centrais dos tr√™s eixos (axial, coronnal e sagital). Anota√ß√£o manual (azul) e sa√≠da do modelo (vermelho).*

# Conclus√£o 

# Pr√≥ximos passos

* Realizar experimentos ao aplicar outras t√©cnicas de aumento de dados, como RandomBlur.
* Testar hiperpar√¢metros da rede, como variar a taxa de aprendizagem e n√∫mero de √©pocas.
* Verificar a normaliza√ß√£o implementada, pois para se ter valores entre -1 e 1 a m√©dia e o desvio padr√£o deixaram de ser 0 e 1, respectivamente.

## Refer√™ncias

Lucena, O., Souza, R., Rittner, L., Frayne, R., & Lotufo, R. (2018, April). Silver standard masks for data augmentation applied to deep-learning-based skull-stripping. In 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018) (pp. 1114-1117). IEEE.

Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.

Carmo, D., Silva, B., Yasuda, C., Rittner, L., & Lotufo, R. (2021). Hippocampus segmentation on epilepsy and Alzheimer's disease studies with multiple convolutional neural networks. Heliyon, 7(2).
