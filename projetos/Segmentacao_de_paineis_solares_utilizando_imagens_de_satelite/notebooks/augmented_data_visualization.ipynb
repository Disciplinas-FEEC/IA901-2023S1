{"cells":[{"cell_type":"markdown","metadata":{"id":"dymA_7bPRrKe"},"source":["# Segmentação de painéis solares utilizando imagens de satélite\n","---\n","# Solar Panel Segmentation Using Satellite Imagery\n","\n","This script is used to visualize the data augmentations."]},{"cell_type":"markdown","metadata":{"id":"CqVUHnV_qram"},"source":["## Library Imports\n","\n","In this section, a connection is established with Google Drive files. Ensure that you have a direct access shortcut to the folder named \"Segmentacao_de_paineis_solares_utilizando_imagens_de_satelite.\" Additionally, the necessary Python libraries are imported for the proper functioning of the code."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22759,"status":"ok","timestamp":1687727033423,"user":{"displayName":"Juan Carlos Cortez Aucapiña","userId":"18336424016162230804"},"user_tz":180},"id":"4mSLOWBZuZIj","outputId":"dcdceeae-e243-4a20-da20-3a47355ffeb1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"9faP3pXmpdiW","executionInfo":{"status":"ok","timestamp":1687727037276,"user_tz":180,"elapsed":3856,"user":{"displayName":"Juan Carlos Cortez Aucapiña","userId":"18336424016162230804"}}},"outputs":[],"source":["import zipfile\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import os\n","import numpy as np\n","import sklearn.model_selection\n","import sklearn.utils.class_weight\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout\n","from tensorflow.keras.optimizers import Adam\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.applications import ResNet50\n","import random\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import pandas as pd\n","import json\n"]},{"cell_type":"markdown","metadata":{"id":"84w1KcfRmBpq"},"source":["## Config\n","\n","In this section, it is possible to define the dataset, the balance between masked and unmasked images, and the file paths to load and save results of data augmentation. Finally, the satellite images and mask of the dataset are unzipped in the Google Colab environment."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ROfihZEpwE2d","executionInfo":{"status":"ok","timestamp":1687727979553,"user_tz":180,"elapsed":284,"user":{"displayName":"Juan Carlos Cortez Aucapiña","userId":"18336424016162230804"}}},"outputs":[],"source":["## PARAMETER SETTINGS\n","db = 'google' # dataset; options: google, ign.\n","opt_databalance = '8020' # (masked/unmasked); options: 9010, 8020, 7030.\n","batch_size = 8 # maximum 16 due to limitations of free colab.\n","num_images = 5\n","\n","## FILE PATHS\n","origin_dataset_path = \"/content/gdrive/MyDrive/Segmentacao_de_paineis_solares_utilizando_imagens_de_satelite/data/raw/bdappv.zip\"\n","dataset_path = \"/content/\"\n","image_folder = f'{dataset_path}bdappv/{db}/img'\n","mask_folder = f'{dataset_path}bdappv/{db}/mask'\n","black_mask = '/content/gdrive/MyDrive/Segmentacao_de_paineis_solares_utilizando_imagens_de_satelite/data/interim/empty_mask.png'\n","path_dic_dataset = f'/content/gdrive/MyDrive/Segmentacao_de_paineis_solares_utilizando_imagens_de_satelite/data/interim/jsons/output_google_{opt_databalance}.json'\n","model_data_augmentation_path = f'/content/gdrive/MyDrive/Segmentacao_de_paineis_solares_utilizando_imagens_de_satelite/assets/data_augmentation.svg'"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Qb0fWxHau18Y","executionInfo":{"status":"ok","timestamp":1687727213181,"user_tz":180,"elapsed":117507,"user":{"displayName":"Juan Carlos Cortez Aucapiña","userId":"18336424016162230804"}}},"outputs":[],"source":["with zipfile.ZipFile(origin_dataset_path, 'r') as zip_ref:\n","    zip_ref.extractall(dataset_path)"]},{"cell_type":"markdown","metadata":{"id":"ZiOQPv0PmZJd"},"source":["## Fuctions\n","\n","In this section, the functions used for loading and plotting data augmentation."]},{"cell_type":"markdown","metadata":{"id":"1RxJ5l1_xBUp"},"source":["### Loading & Pre-processing"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"i3zKpJCLmakm","executionInfo":{"status":"ok","timestamp":1687728695179,"user_tz":180,"elapsed":298,"user":{"displayName":"Juan Carlos Cortez Aucapiña","userId":"18336424016162230804"}}},"outputs":[],"source":["def read_dataset_as_dataframe(path_dic_dataset, name_ds): #path_save_df\n","    \"\"\"\n","    Read a JSON file containing dataset data and create a DataFrame from it.\n","\n","    Args:\n","        path_dic_dataset (str): Path to the JSON file containing the dataset data.\n","        name_ds (str): Name of the dataset in the 'query' key in the JSON file.\n","        # path_save_df (str): Path to save the resulting DataFrame in CSV format.\n","\n","    Returns:\n","        pandas.DataFrame: DataFrame with the randomized dataset data.\n","    \"\"\"\n","    with open(path_dic_dataset, 'r') as file:\n","        data = json.load(file)\n","    query = data[name_ds]\n","    img_files = []\n","    mask_files = []\n","    for label in query.keys():\n","        files_query = query[label][0]\n","        for file_i in files_query:\n","            img_files.append(file_i[0])\n","            mask_files.append(file_i[1])\n","    df = pd.DataFrame()\n","    df['imgs'] = img_files\n","    df['masks'] = mask_files\n","    df_random = df.sample(frac=1).reset_index(drop=True)\n","    #df_random.to_csv(f'{path_save_df}df_random_{name_ds}.csv', index=False)\n","    return df_random\n","\n","def load_and_preprocess_image(path):\n","    \"\"\"\n","    Loads and preprocesses an image from the given file path.\n","\n","    Args:\n","        path (str): File path of the image to be loaded and preprocessed.\n","\n","    Returns:\n","        tf.Tensor: Preprocessed image tensor ready for further processing or analysis.\n","                   The tensor has the shape (height, width, channels) and the pixel values are normalized to the range [0, 1].\n","    \"\"\"\n","    image = tf.io.read_file(path)\n","    image = tf.image.decode_png(image, channels=3)\n","    image = tf.image.convert_image_dtype(image, tf.float32)\n","    return image\n","\n","\n","def load_and_preprocess_mask(path):\n","    \"\"\"\n","    Loads and preprocesses a mask from the given file path.\n","\n","    Args:\n","        path (str): File path of the mask to be loaded and preprocessed.\n","\n","    Returns:\n","        tf.Tensor: Preprocessed mask tensor ready for further processing or analysis.\n","                   The tensor has the shape (height, width, 1) and the pixel values are normalized to the range [0, 1].\n","    \"\"\"\n","    mask = tf.io.read_file(path)\n","    mask = tf.image.decode_png(mask, channels=1)\n","    mask = tf.image.convert_image_dtype(mask, tf.float32)\n","    return mask\n","\n","\n","def data_augmentation(image, mask, size=400, zoom_range=(0.7, 1.2)):\n","    \"\"\"\n","    Applies random data augmentation operations to the given image and mask.\n","    Random rotation and flip\n","    Random zoom\n","    Random brightness, contrast, and saturation adjustments\n","\n","    Args:\n","        image (tf.Tensor): Image tensor to be augmented.\n","                           The tensor has the shape (height, width, channels) and the pixel values are normalized to the range [0, 1].\n","        mask (tf.Tensor): Mask tensor to be augmented.\n","                          The tensor has the shape (height, width, 1) and the pixel values are normalized to the range [0, 1].\n","        size (int): Desired size for the augmented image and mask (both height and width).\n","        zoom_range (tuple): Range for random zooming. It is specified as a tuple (min_zoom, max_zoom), where values should be between 0 and 1.\n","\n","    Returns:\n","        tf.Tensor: Augmented image tensor.\n","                   The tensor has the shape (size, size, channels) and the pixel values are normalized to the range [0, 1].\n","        tf.Tensor: Augmented mask tensor.\n","                   The tensor has the shape (size, size, 1) and the pixel values are normalized to the range [0, 1].\n","    \"\"\"\n","    # Apply random rotation and flip\n","    combined = tf.concat([image, mask], axis=-1)\n","    combined = tf.image.random_flip_left_right(combined)\n","    combined = tf.image.random_flip_up_down(combined)\n","\n","    rotation_angle = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32) * 90\n","    combined = tf.image.rot90(combined, k=rotation_angle // 90)\n","\n","    # Perform random zoom\n","    zoom_factor = tf.random.uniform([], zoom_range[0], zoom_range[1])\n","    combined_dims = tf.cast(tf.shape(combined)[:2], tf.float32)\n","    new_dims = tf.cast(combined_dims * zoom_factor, tf.int32)\n","    combined_resized = tf.image.resize(combined, new_dims)\n","    combined = tf.image.resize_with_crop_or_pad(combined_resized, size, size)\n","\n","    # Split image and mask\n","    image = combined[:, :, :3]\n","    mask = combined[:, :, 3:]\n","\n","    # Apply random brightness, contrast, and saturation adjustments\n","    image = tf.image.random_brightness(image, max_delta=0.1)\n","    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n","    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n","    image = tf.clip_by_value(image, 0, 1)  # Ensure values are in the [0, 1] range\n","\n","    return image, mask\n","\n","\n","def random_augmentation(image, mask, augment_prob, size=400, zoom_range=(0.7, 1.2)):\n","    \"\"\"\n","    Applies random data augmentation operations to the given image and mask with a given probability.\n","\n","    Args:\n","        image (tf.Tensor): Image tensor to be augmented.\n","                           The tensor has the shape (height, width, channels) and the pixel values are normalized to the range [0, 1].\n","        mask (tf.Tensor): Mask tensor to be augmented.\n","                          The tensor has the shape (height, width, 1) and the pixel values are normalized to the range [0, 1].\n","        augment_prob (float): Probability of applying data augmentation operations.\n","                              Should be a value between 0 and 1.\n","        size (int): Desired size for the augmented image and mask (both height and width).\n","        zoom_range (tuple): Range for random zooming. It is specified as a tuple (min_zoom, max_zoom), where values should be between 0 and 1.\n","\n","    Returns:\n","        tf.Tensor: Augmented image tensor.\n","                   The tensor has the shape (size, size, channels) and the pixel values are normalized to the range [0, 1].\n","        tf.Tensor: Augmented mask tensor.\n","                   The tensor has the shape (size, size, 1) and the pixel values are normalized to the range [0, 1].\n","    \"\"\"\n","    if tf.random.uniform(shape=[], minval=0, maxval=1) < augment_prob:\n","        return data_augmentation(image, mask, size, zoom_range)\n","    else:\n","        return image, mask\n","\n","\n","def tf_data_generator(image_files, mask_files, batch_size, size=400, zoom_range=(0.7, 1.2)):\n","    \"\"\"\n","    Generates batches of preprocessed image and mask data using TensorFlow's tf.data API.\n","\n","    Args:\n","        image_files (list): List of image file paths.\n","        mask_files (list): List of mask file paths.\n","        batch_size (int): Batch size.\n","        size (int): Desired size for resizing the image and mask (both height and width).\n","        zoom_range (tuple): Range for random zooming. It is specified as a tuple (min_zoom, max_zoom), where values should be between 0 and 1.\n","\n","    Returns:\n","        tf.data.Dataset: Dataset containing batches of preprocessed image and mask data.\n","    \"\"\"\n","    # Convert the lists of file paths to tf.data Datasets\n","    image_dataset = tf.data.Dataset.from_tensor_slices(image_files)\n","    mask_dataset = tf.data.Dataset.from_tensor_slices(mask_files)\n","\n","    # Use map to load and preprocess the image and mask data in parallel\n","    image_dataset = image_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n","    mask_dataset = mask_dataset.map(load_and_preprocess_mask, num_parallel_calls=tf.data.AUTOTUNE)\n","\n","    # Combine the image and mask datasets\n","    dataset = tf.data.Dataset.zip((image_dataset, mask_dataset))\n","\n","    # Batch the data\n","    dataset = dataset.batch(batch_size)\n","\n","    # Prefetch data for improved performance\n","    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n","\n","    return dataset\n","\n","def tf_data_generator_train(image_files, mask_files, batch_size, num_epochs, augment_prob, size=400, zoom_range=(0.7, 1.2)):\n","    \"\"\"\n","    Generates batches of preprocessed image and mask data using TensorFlow's tf.data API.\n","\n","    Args:\n","        image_files (list): List of image file paths.\n","        mask_files (list): List of mask file paths.\n","        batch_size (int): Batch size.\n","        num_epochs (int): Number of epochs.\n","        augment_prob (float): Probability of applying data augmentation operations.\n","                              Should be a value between 0 and 1.\n","        size (int): Desired size for resizing the image and mask (both height and width).\n","        zoom_range (tuple): Range for random zooming. It is specified as a tuple (min_zoom, max_zoom), where values should be between 0 and 1.\n","\n","    Returns:\n","        tf.data.Dataset: Dataset containing batches of preprocessed image and mask data.\n","    \"\"\"\n","\n","    # Convert the lists of file paths to tf.data Datasets\n","    image_dataset = tf.data.Dataset.from_tensor_slices(image_files)\n","    mask_dataset = tf.data.Dataset.from_tensor_slices(mask_files)\n","\n","    # Use map to load and preprocess the image and mask data in parallel\n","    image_dataset = image_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n","    mask_dataset = mask_dataset.map(load_and_preprocess_mask, num_parallel_calls=tf.data.AUTOTUNE)\n","\n","    # Combine the image and mask datasets\n","    dataset = tf.data.Dataset.zip((image_dataset, mask_dataset))\n","\n","    # Apply random data augmentation\n","    dataset = dataset.map(lambda image, mask: random_augmentation(image, mask, augment_prob, size, zoom_range), num_parallel_calls=tf.data.AUTOTUNE)\n","\n","    # Shuffle the dataset\n","    dataset = dataset.shuffle(buffer_size=100)\n","\n","    # Repeat the dataset indefinitely\n","    dataset = dataset.repeat(num_epochs)\n","\n","    # Batch the data\n","    dataset = dataset.batch(batch_size)\n","\n","    # Prefetch data for improved performance\n","    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n","\n","    return dataset\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Uik3YhKXJ_JV"},"source":["### Plots"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ehE546pwJ-lR","executionInfo":{"status":"ok","timestamp":1687728222973,"user_tz":180,"elapsed":281,"user":{"displayName":"Juan Carlos Cortez Aucapiña","userId":"18336424016162230804"}}},"outputs":[],"source":["def display_augmented_images(image_files, mask_files, num_images,model_data_augmentation_path):\n","    \"\"\"\n","    Displays a set of images and their augmented versions side by side.\n","\n","    Args:\n","        image_files (list): List of image file paths.\n","        mask_files (list): List of mask file paths.\n","        num_images (int): Number of images to display.\n","    \"\"\"\n","    if len(image_files) != len(mask_files):\n","        raise ValueError(\"image_files and mask_files must have the same length\")\n","\n","    # Combine image and mask files into pairs\n","    pairs = list(zip(image_files, mask_files))\n","\n","    # Randomly select a unique set of pairs (image, mask)\n","    selected_pairs = random.sample(pairs, num_images)\n","    i = 0\n","    for image_path, mask_path in selected_pairs:\n","        image = load_and_preprocess_image(image_path)\n","        mask = load_and_preprocess_mask(mask_path)\n","\n","        augmented_image, augmented_mask = data_augmentation(image, mask)\n","\n","        # Plot the original image and mask\n","        fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n","\n","        ax[0].imshow(image)\n","        ax[0].set_title(\"Original Image\")\n","        ax[0].axis('off')\n","\n","        ax[1].imshow(mask[:,:,0], cmap='gray')\n","        ax[1].set_title(\"Original Mask\")\n","        ax[1].axis('off')\n","\n","        # Plot the augmented image and mask\n","        ax[2].imshow(augmented_image)\n","        ax[2].set_title(\"Augmented Image\")\n","        ax[2].axis('off')\n","\n","        ax[3].imshow(augmented_mask[:,:,0], cmap='gray')\n","        ax[3].set_title(\"Augmented Mask\")\n","        ax[3].axis('off')\n","\n","        plt.savefig(f'{model_data_augmentation_path[:-4]}_sample{i}{model_data_augmentation_path[-4:]}', bbox_inches='tight', pad_inches=0.02)\n","\n","        plt.show()\n","        i = i+1\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9E3o1_Xvmilt"},"source":["## Main\n","\n","The main section of the code contains the read dataset subsection and the visualization of data augmentation."]},{"cell_type":"markdown","metadata":{"id":"l8--ObCD0w7h"},"source":["### Read dataset"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Vi9xo8JIgrj8","executionInfo":{"status":"ok","timestamp":1687728066443,"user_tz":180,"elapsed":1289,"user":{"displayName":"Juan Carlos Cortez Aucapiña","userId":"18336424016162230804"}}},"outputs":[],"source":["df_train = read_dataset_as_dataframe(path_dic_dataset, 'train')\n","train_img_files = list(df_train['imgs'].values)\n","train_mask_files = list(df_train['masks'].values)"]},{"cell_type":"markdown","metadata":{"id":"5R6kQkbiXUsK"},"source":["### Visualize Data Augmentation"]},{"cell_type":"code","source":["display_augmented_images(train_img_files, train_mask_files, num_images,model_data_augmentation_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1gHNAs74KIHhiZ83_7Ol77hY2NQR4JFC9"},"id":"qJRo_-GhX4nB","executionInfo":{"status":"ok","timestamp":1687728245541,"user_tz":180,"elapsed":6352,"user":{"displayName":"Juan Carlos Cortez Aucapiña","userId":"18336424016162230804"}},"outputId":"e092307b-cc4b-4f41-d273-d3afbc1a1c8b"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["CqVUHnV_qram","84w1KcfRmBpq","ZiOQPv0PmZJd","1RxJ5l1_xBUp","Uik3YhKXJ_JV","9E3o1_Xvmilt","l8--ObCD0w7h","5R6kQkbiXUsK"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}