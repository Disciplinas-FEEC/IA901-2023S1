{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange> Installs </font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install tensorflow\n",
    "\n",
    "pip install keras\n",
    "\n",
    "pip install imblearn\n",
    "\n",
    "pip install matplotlib\n",
    "\n",
    "pip install seaborn\n",
    "\n",
    "pip install scikit-learn\n",
    "\n",
    "pip install numpy pandas scipy nibabel pillow scikit-image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange> Importing Libraries </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "from PIL import Image\n",
    "from skimage.util import img_as_ubyte\n",
    "import nibabel as nib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange> Define directory of dataset & Classes names </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your data paths and classes\n",
    "\n",
    "source_dir = 'C:\\\\Users\\\\pedro\\\\iCloudDrive\\\\Academics\\\\UNICAMP\\\\2023\\\\IA901\\\\Projeto\\\\ADNI\\\\MPRAGE_all\\\\Data\\\\' # ADNI Raw data (3D MRI Volumes) \n",
    "interim_dir0 = 'C:\\\\Users\\\\pedro\\\\Project\\\\Datasets\\\\ADNI0' #ADNI slice selected, separado em suas labels e em subfolders de cada sess√£o de MRI\n",
    "interim_dir1 = 'C:\\\\Users\\\\pedro\\\\Project\\\\Datasets\\\\ADNI1' #ADNI slice selected, separado em suas labels\n",
    "final_di r= 'C:\\\\Users\\\\pedro\\\\Project\\\\Datasets\\\\ADNI3' #ADNI slice selected, separado em suas labels, em train, test, val (subjects unicos)\n",
    "classes = ['AD', 'CN', 'EMCI', 'LMCI', 'MCI']\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange> Slice Selection and Label Separation </font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes the ADNI dataset csv table and the raw ADNI data (3D MRI Volumes) and selects 10 slices based on highest entropy values and reorganizes it into label based folders ['AD', 'CN', 'EMCI', 'LMCI', 'MCI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading ADNI table\n",
    "df = pd.read_csv('MPRAGE_all.csv')\n",
    "groupLabels = df['Group']\n",
    "groupNames = groupLabels.unique()\n",
    "\n",
    "for groupName in groupNames:\n",
    "    count = sum(groupLabels == groupName)\n",
    "    print(f'{groupName}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_ids = [name for name in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, name))]\n",
    "\n",
    "for i, subject_id in enumerate(subject_ids): # Looping over all subjects\n",
    "    subjectGroup = df.loc[df['Subject'] == subject_id, 'Group'].values[0] # Getting the group of the current subject \n",
    "    fileList = [os.path.join(dp, f) for dp, dn, filenames in os.walk(os.path.join(source_dir, subject_id, 'MPRAGE')) for f in filenames if os.path.splitext(f)[1] == '.nii']\n",
    "    print(f'{(i/len(subject_ids))*100:.2f}%')\n",
    "\n",
    "    for file in fileList: # Looping over all image files \n",
    "        try:\n",
    "            X = nib.load(file).get_fdata() # Extract the image data from the structure\n",
    "        except Exception as e:\n",
    "            print(f'Problem using nib.load for file: {file}. \\nError: {str(e)}')\n",
    "            continue\n",
    "\n",
    "        imagefoldername = os.path.join(interim_dir0, subjectGroup, 'slices_' + os.path.basename(file))\n",
    "        os.makedirs(imagefoldername, exist_ok=True)\n",
    "\n",
    "        # Get entropy values for slices \n",
    "        val = [entropy(img / img.max()) if img.max() > 0 else 0 for img in X[:,:,120:]]\n",
    "\n",
    "        # Get indices of slices sorted by entropy\n",
    "        Xind = np.argsort(val)[::-1]\n",
    "\n",
    "        for n in range(10): # Generate jpg images of the 10 highest entropy slices\n",
    "            img = img_as_ubyte(X[:,:,Xind[n]])\n",
    "            Image.fromarray(img).save(os.path.join(imagefoldername, f'{n:02d}.jpg'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange> Extraindo e renomeando as slices de seus respectivos subfolders </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each class, move the first 10 images from each subfolder\n",
    "for cls in classes:\n",
    "    # Get the path to the current class folder in both source and destination\n",
    "    src_cls_path = os.path.join(source_path, cls)\n",
    "    dst_cls_path = os.path.join(destination_path, cls)\n",
    "    \n",
    "    # For each subfolder in the current class folder\n",
    "    for subfolder in os.listdir(src_cls_path):\n",
    "        # Get the path to the current subfolder\n",
    "        src_subfolder_path = os.path.join(src_cls_path, subfolder)\n",
    "\n",
    "        # Get a list of all the image files in the current subfolder\n",
    "        all_files = os.listdir(src_subfolder_path)\n",
    "\n",
    "        # Sort the list and take the first 10 images\n",
    "        all_files.sort()\n",
    "        images_to_move = all_files\n",
    "\n",
    "        # For each image to move\n",
    "        for image_file in images_to_move:\n",
    "            # Get the path to the image in the source folder\n",
    "            src_image_path = os.path.join(src_subfolder_path, image_file)\n",
    "            \n",
    "            # Create a new image name by prepending the subfolder's name to the original image's name\n",
    "            new_image_name = f\"{subfolder}_{image_file}\"\n",
    "            # Get the path to where the image will be in the destination folder\n",
    "            dst_image_path = os.path.join(dst_cls_path, new_image_name)\n",
    "\n",
    "            # Move the image\n",
    "            shutil.copy2(src_image_path, dst_image_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange> Testing, validation and training split </font>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating test, val and train sets making sure there is no subject overlap, i.e., there is no subject whose images are in two sets of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expression to match and extract the subject id from the filename\n",
    "subject_id_regex = re.compile(r\"S_(\\d+)\")\n",
    "def get_subject_id(filename):\n",
    "    match = subject_id_regex.search(filename)\n",
    "    return match.group(1) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m subject_id \u001b[39m=\u001b[39m get_subject_id(img)\n\u001b[0;32m     21\u001b[0m \u001b[39mif\u001b[39;00m subject_id \u001b[39min\u001b[39;00m train_subject_ids:\n\u001b[1;32m---> 22\u001b[0m     shutil\u001b[39m.\u001b[39;49mcopy2(img, dest_dir \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mtrain\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39mcls\u001b[39;49m)\n\u001b[0;32m     23\u001b[0m \u001b[39melif\u001b[39;00m subject_id \u001b[39min\u001b[39;00m val_subject_ids:\n\u001b[0;32m     24\u001b[0m     shutil\u001b[39m.\u001b[39mcopy2(img, dest_dir \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mval\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mcls\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1264.0_x64__qbz5n2kfra8p0\\Lib\\shutil.py:436\u001b[0m, in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(dst):\n\u001b[0;32m    435\u001b[0m     dst \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(dst, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(src))\n\u001b[1;32m--> 436\u001b[0m copyfile(src, dst, follow_symlinks\u001b[39m=\u001b[39;49mfollow_symlinks)\n\u001b[0;32m    437\u001b[0m copystat(src, dst, follow_symlinks\u001b[39m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    438\u001b[0m \u001b[39mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1264.0_x64__qbz5n2kfra8p0\\Lib\\shutil.py:276\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[39m# Windows, see:\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[39m# https://github.com/python/cpython/pull/7160#discussion_r195405230\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[39melif\u001b[39;00m _WINDOWS \u001b[39mand\u001b[39;00m file_size \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 276\u001b[0m     _copyfileobj_readinto(fsrc, fdst, \u001b[39mmin\u001b[39;49m(file_size, COPY_BUFSIZE))\n\u001b[0;32m    277\u001b[0m     \u001b[39mreturn\u001b[39;00m dst\n\u001b[0;32m    279\u001b[0m copyfileobj(fsrc, fdst)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1264.0_x64__qbz5n2kfra8p0\\Lib\\shutil.py:180\u001b[0m, in \u001b[0;36m_copyfileobj_readinto\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mmemoryview\u001b[39m(\u001b[39mbytearray\u001b[39m(length)) \u001b[39mas\u001b[39;00m mv:\n\u001b[0;32m    179\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 180\u001b[0m         n \u001b[39m=\u001b[39m fsrc_readinto(mv)\n\u001b[0;32m    181\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n:\n\u001b[0;32m    182\u001b[0m             \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for cls in classes:\n",
    "    os.makedirs(dest_dir + '\\\\train\\\\' + cls, exist_ok=True)\n",
    "    os.makedirs(dest_dir + '\\\\val\\\\' + cls, exist_ok=True)\n",
    "    os.makedirs(dest_dir + '\\\\test\\\\' + cls, exist_ok=True)\n",
    "\n",
    "    # Get a list of all the images\n",
    "    images = glob.glob(source_dir + '\\\\' + cls + '\\\\*.jpg')\n",
    "\n",
    "    # Extract the unique subject IDs\n",
    "    subject_ids = list(set(get_subject_id(image) for image in images))\n",
    "    np.random.shuffle(subject_ids)\n",
    "\n",
    "    # Split into training, validation, and test datasets\n",
    "    train_subject_ids, val_subject_ids, test_subject_ids = np.split(\n",
    "        np.array(subject_ids),\n",
    "        [int(len(subject_ids)* train_ratio), int(len(subject_ids)* (train_ratio + val_ratio))])\n",
    "\n",
    "    # Copy the files\n",
    "    for img in images:\n",
    "        subject_id = get_subject_id(img)\n",
    "        if subject_id in train_subject_ids:\n",
    "            shutil.copy2(img, dest_dir + '\\\\train\\\\' + cls)\n",
    "        elif subject_id in val_subject_ids:\n",
    "            shutil.copy2(img, dest_dir + '\\\\val\\\\' + cls)\n",
    "        elif subject_id in test_subject_ids:\n",
    "            shutil.copy2(img, dest_dir + '\\\\test\\\\' + cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in ['AD']:\n",
    "    os.makedirs(dest_dir + '\\\\train\\\\' + cls, exist_ok=True)\n",
    "    os.makedirs(dest_dir + '\\\\val\\\\' + cls, exist_ok=True)\n",
    "    os.makedirs(dest_dir + '\\\\test\\\\' + cls, exist_ok=True)\n",
    "\n",
    "    # Get a list of all the images\n",
    "    images = glob.glob(source_dir + '\\\\' + cls + '\\\\*.jpg')\n",
    "\n",
    "    # Extract the unique subject IDs\n",
    "    subject_ids = list(set(get_subject_id(image) for image in images))\n",
    "    np.random.shuffle(subject_ids)\n",
    "\n",
    "    # Split into training, validation, and test datasets\n",
    "    train_subject_ids, val_subject_ids, test_subject_ids = np.split(\n",
    "        np.array(subject_ids),\n",
    "        [int(len(subject_ids)* train_ratio), int(len(subject_ids)* (train_ratio + val_ratio))])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['1059', '1137', '0010', '1037', '4280', '4733', '0341', '4730',\n",
       "        '0724', '0682', '0404', '4110', '4894', '1253', '0805', '1205',\n",
       "        '1082', '5074', '0083', '0753', '5149', '4172', '5184', '5016',\n",
       "        '1296', '0029', '4672', '4792', '0400', '0733', '0053', '0183',\n",
       "        '0335', '1144', '5240', '0689', '5163', '0007', '4615', '5210',\n",
       "        '1391', '5162', '4526', '0003', '4859', '1263', '4912', '0535',\n",
       "        '1101', '4772', '4770', '0219', '5275', '5146', '0228', '4994',\n",
       "        '1368', '0543', '4827', '4589', '5090', '0286', '5120', '4696',\n",
       "        '0487', '4124', '0816', '0777', '0084', '4755', '0372', '1373',\n",
       "        '0696', '0790', '1289', '0474', '0110', '0216', '4024', '5112',\n",
       "        '5087', '1377', '4982', '1157', '5205', '4001', '4990', '5013',\n",
       "        '4719', '5017', '1257', '4993', '4905', '4783', '5252', '1079',\n",
       "        '4971', '1024', '4223', '5019', '5231', '0147', '4980', '0565',\n",
       "        '0853', '0720', '5015', '5018', '0699', '5106', '0492', '4657',\n",
       "        '4906', '1435', '5071', '4820', '4863', '5006', '0829', '4660',\n",
       "        '4984', '4338', '0392', '0213', '0374', '5138', '4192', '1185',\n",
       "        '0167', '1001', '5208', '1083', '5012', '4732', '5005', '0953',\n",
       "        '5123', None, '4997', '1161', '5059', '4625', '1081', '0828',\n",
       "        '4546', '0266', '1371', '0592', '0129', '1207', '4477'],\n",
       "       dtype=object),\n",
       " array(['5224', '4252', '4968', '4853', '4537', '1262', '0093', '0340',\n",
       "        '4879', '0793', '4676', '1192', '0759', '0996', '5063', '4039',\n",
       "        '0979', '5037', '4549', '0730', '0712', '4153', '4258', '0760',\n",
       "        '4692', '0139', '4774', '0916', '0633', '1170', '1055', '5027'],\n",
       "       dtype=object),\n",
       " ['C:\\\\Users\\\\pedro\\\\Project\\\\Datasets\\\\ADNI2\\\\AD\\\\slices_ADNI_002_S_0816_MR_MPRAGE_br_raw_20060929164645213_1_S19532_I25405.nii_01.jpg',\n",
       "  'C:\\\\Users\\\\pedro\\\\Project\\\\Datasets\\\\ADNI2\\\\AD\\\\slices_ADNI_002_S_0816_MR_MPRAGE_br_raw_20060929164645213_1_S19532_I25405.nii_02.jpg',\n",
       "  'C:\\\\Users\\\\pedro\\\\Project\\\\Datasets\\\\ADNI2\\\\AD\\\\slices_ADNI_002_S_0816_MR_MPRAGE_br_raw_20060929164645213_1_S19532_I25405.nii_03.jpg',\n",
       "  'C:\\\\Users\\\\pedro\\\\Project\\\\Datasets\\\\ADNI2\\\\AD\\\\slices_ADNI_002_S_0816_MR_MPRAGE_br_raw_20060929164645213_1_S19532_I25405.nii_04.jpg',\n",
       "  'C:\\\\Users\\\\pedro\\\\Project\\\\Datasets\\\\ADNI2\\\\AD\\\\slices_ADNI_002_S_0816_MR_MPRAGE_br_raw_20060929164645213_1_S19532_I25405.nii_05.jpg',\n",
       "  'C:\\\\Users\\\\pedro\\\\Project\\\\Datasets\\\\ADNI2\\\\AD\\\\slices_ADNI_002_S_0816_MR_MPRAGE_br_raw_20060929164645213_1_S19532_I25405.nii_06.jpg',\n",
       "  'C:\\\\Users\\\\pedro\\\\Project\\\\Datasets\\\\ADNI2\\\\AD\\\\slices_ADNI_002_S_0816_MR_MPRAGE_br_raw_20060929164645213_1_S19532_I25405.nii_07.jpg',\n",
       "  'C:\\\\Users\\\\pedro\\\\Project\\\\Datasets\\\\ADNI2\\\\AD\\\\slices_ADNI_002_S_0816_MR_MPRAGE_br_raw_20060929164645213_1_S19532_I25405.nii_08.jpg',\n",
       "  'C:\\\\Users\\\\pedro\\\\Project\\\\Datasets\\\\ADNI2\\\\AD\\\\slices_ADNI_002_S_0816_MR_MPRAGE_br_raw_20060929164645213_1_S19532_I25405.nii_09.jpg',\n",
       "  'C:\\\\Users\\\\pedro\\\\Project\\\\Datasets\\\\ADNI2\\\\AD\\\\slices_ADNI_002_S_0816_MR_MPRAGE_br_raw_20060929164645213_1_S19532_I25405.nii_10.jpg'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subject_ids, val_subject_ids, images[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0816'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = images[1]\n",
    "subject_id = get_subject_id(img)\n",
    "subject_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the files\n",
    "for img in images:\n",
    "        subject_id = get_subject_id(img)\n",
    "        if subject_id in train_subject_ids:\n",
    "            shutil.copy2(img, dest_dir + '\\\\train\\\\' + cls)\n",
    "        elif subject_id in val_subject_ids:\n",
    "            shutil.copy2(img, dest_dir + '\\\\val\\\\' + cls)\n",
    "        elif subject_id in test_subject_ids:\n",
    "            shutil.copy2(img, dest_dir + '\\\\test\\\\' + cls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
