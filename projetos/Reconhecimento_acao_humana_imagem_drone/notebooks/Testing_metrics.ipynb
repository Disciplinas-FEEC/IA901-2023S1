{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Debora-Simoes/IA901-2023S1/blob/main/projetos/Reconhecimento_acao_humana_imagem_drone/notebooks/Testing_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfNKKWBohtUn",
        "outputId": "cfffafd8-8a26-40b7-95da-c64734a83699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1r9oHXQ5JU33TQMJZYU2USd04KCn98S1_/IA901_Projeto/yolov7\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "## Going to our repository clone and installing dependencies\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/IA901_Projeto/yolov7\n",
        "!pip install -qr requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Give a title with name in the same format as the default example (not special char, no space)\n",
        "EXPERIMENT_TITLE = \"no_preprocessing_experiment1\"\n",
        "\n",
        "# Img size\n",
        "SIZE = 640\n",
        "\n",
        "# How many samples per iteration will be processed\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# How many epochs\n",
        "EPOCHS = 20\n",
        "\n",
        "# Model name (which must have the pretrained weights in our folder, if not, must download it)\n",
        "PRETRAINED_MODEL = \"yolov7\"\n",
        "\n",
        "# Number of asynchronous workers (you don't have to change it)\n",
        "WORKERS = 4\n",
        "\n",
        "# Experiment parent folder name (you don't have to change it)\n",
        "PROJECT = \"human_action_detection_in_drone_images\"\n",
        "\n",
        "# Experiment child name (MUST CHANGE IT)\n",
        "RUN_NAME = f\"{PRETRAINED_MODEL}_size{SIZE}_epochs{EPOCHS}_batch{BATCH_SIZE}\"\n",
        "\n",
        "# Path to our data which must have \"train/images\", \"train/labels\", \"val/images\" and \"val/labels\" folders\n",
        "PATH = \"/content/drive/MyDrive/IA901_Projeto/Dados_pre_processing/Filtro_Sobel/\"\n",
        "\n",
        "# Number of unique classes (labels)\n",
        "N_CLASSES = 4\n",
        "\n",
        "# Define classes names (must have the same length as N_CLASSES)\n",
        "CLASSES = ['walk', 'riding', 'stand', 'sit']\n",
        "\n",
        "# SAVING CONFIGURATIONS\n",
        "import yaml\n",
        "config = {'path': PATH,\n",
        "         'train': PATH + 'test/',\n",
        "         'val': PATH + 'Teste/',\n",
        "         'nc': N_CLASSES,\n",
        "         'names': CLASSES}\n",
        "\n",
        "with open(\"data.yaml\", \"w\") as file:\n",
        "    yaml.dump(config, file, default_flow_style=False)"
      ],
      "metadata": {
        "id": "xF4F40APA8U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "!wandb disabled\n",
        "\n",
        "!python test.py --iou-thres 0.5 --conf-thres 0.1 --img 640 --batch 16 --data ./data.yaml --weights /content/drive/MyDrive/IA901_Projeto/yolov7/SOBEL/sobel_run_2/weights/best.pt --project 'SOBEL' --name 'checking_run5' --exist-ok --save-conf --save-txt --save-json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8WPMxfa2jp9",
        "outputId": "2b042aef-1073-4b3b-f72e-2e1c9adc8952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: wandb: command not found\n",
            "Namespace(weights=['/content/drive/MyDrive/IA901_Projeto/yolov7/SOBEL/sobel_run_2/weights/best.pt'], data='./data.yaml', batch_size=16, img_size=640, conf_thres=0.1, iou_thres=0.5, task='val', device='', single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=True, project='SOBEL', name='checking_run5', exist_ok=True, no_trace=False, v5_metric=False)\n",
            "YOLOR üöÄ v0.1-122-g3b41c2c torch 2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 306 layers, 36496081 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/IA901_Projeto/Dados_pre_processing/Filtro_Sobel/Teste/labels.cache' images and labels... 1252 found, 14 missing, 0 empty, 0 corrupted: 100% 1266/1266 [00:00<?, ?it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 80/80 [37:26<00:00, 28.08s/it]\n",
            "                 all        1266           0           0           0           0           0\n",
            "Speed: 1734.1/0.1/1734.2 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "/usr/local/lib/python3.10/dist-packages/seaborn/matrix.py:202: RuntimeWarning: All-NaN slice encountered\n",
            "  vmin = np.nanmin(calc_data)\n",
            "/usr/local/lib/python3.10/dist-packages/seaborn/matrix.py:207: RuntimeWarning: All-NaN slice encountered\n",
            "  vmax = np.nanmax(calc_data)\n",
            "Results saved to SOBEL/checking_run5\n",
            "0 labels saved to SOBEL/checking_run5/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Js_ZnkYqK7iE"
      }
    }
  ]
}