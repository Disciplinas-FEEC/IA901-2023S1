{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_85BzfHE4Gvx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import zipfile\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDlGASBv4Gv7"
      },
      "source": [
        "Exemplos de parâmetros para data augmentation:\n",
        "*  rotation_range: faixa de graus para rotações aleatórias;\n",
        "*  width_shift_range e height_shift_range: fração da largura e algura total;\n",
        "*  shear_range: ângulo de cisalhamento no sentido anti-horário em graus;\n",
        "*  zoom_range: intervalo para zoom aleatório;\n",
        "*  horizontal_flip: inverte aleatoriamente as entradas horizontalmente; e\n",
        "*  fill_mode: tipo de preenchimento que será realizado fora dos limites de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VApEj-ZB4GwE"
      },
      "outputs": [],
      "source": [
        "# Aplicando o augmentation que será definido em todas as imagens do treino e validação\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "def modify_hue(image):\n",
        "    image_hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "    hue_shift = random.uniform(-0.1, 0.1)\n",
        "    image_hsv[:,:,0] += hue_shift\n",
        "    image_hsv[:,:,0] = np.clip(image_hsv[:,:,0], 0, 1)\n",
        "    image_rgb = cv2.cvtColor(image_hsv, cv2.COLOR_HSV2RGB)\n",
        "    return image_rgb\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "def preprocess_image(image):\n",
        "    modified_image = modify_hue(image)\n",
        "    standardized_image = preprocess_input(modified_image)\n",
        "    return standardized_image\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=0,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    brightness_range=[0.7, 1.3],\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=preprocess_image,\n",
        ")\n",
        " \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/Shareddrives/IA901/dados melanoma/data/interim/treino',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=0,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    brightness_range=[0.7, 1.3],\n",
        "    fill_mode='nearest',\n",
        "    preprocessing_function=modify_hue\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "         '/content/drive/Shareddrives/IA901/dados melanoma/data/interim/validacao',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=64,\n",
        "        class_mode='categorical'\n",
        "       )\n",
        "\n",
        "# Visualiza as transformações de augmentation nas imagens\n",
        "for i in range(1):\n",
        "    image = train_generator[0][0][0].astype('uint8')\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(image))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2jfdZuW4GwG"
      },
      "outputs": [],
      "source": [
        "# Calculamos os pesos das classes para que seja penalisado no treino posteriormente\n",
        "classes = np.unique(train_generator.classes)\n",
        "class_counts = np.bincount(train_generator.classes)\n",
        "total_samples = np.sum(class_counts)\n",
        "class_weights = total_samples / (len(classes) * class_counts)\n",
        "\n",
        "train_class_weights = dict(enumerate(class_weights))\n",
        "print(train_class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = tf.keras.optimizers.legacy.SGD(learning_rate=0.001, momentum=0.9, decay=0.01, nesterov=True)\n",
        "\n",
        "model_ResNet50 = tf.keras.Sequential([\n",
        "     tf.keras.applications.ResNet50(\n",
        "        input_shape=(224, 224, 3),\n",
        "        weights='imagenet'\n",
        "    ),\n",
        "    \n",
        "  tf.keras.layers.Reshape((-1, 1, 1000)),  # Reshape to a 4-dimensional tensor\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(2, activation='sigmoid')\n",
        "    \n",
        "])\n",
        "    \n",
        "model_ResNet50.compile(\n",
        "    optimizer=sgd, metrics=['AUC'],\n",
        "    loss = 'binary_crossentropy',\n",
        ")"
      ],
      "metadata": {
        "id": "MQDBmRVY_zyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We reduce significantly number of trainable parameters by freezing certain layers, excluding from training, i.e. their weights will never be updated\n",
        "\n",
        "# freeze the first 1 layer\n",
        "\n",
        "model_ResNet50.layers[0].trainable = False\n",
        "for layer in model_ResNet50.layers[:5]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_ResNet50.summary()"
      ],
      "metadata": {
        "id": "x17RzKrq_zV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVys5qir4GwI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Reshape, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "tf.config.run_functions_eagerly(True) # otherwise error\n",
        "\n",
        "# Callbacks\n",
        "cb_early_stopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "cb_checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='/content/drive/Shareddrives/IA901/dados melanoma/models/', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "\n",
        "callbacks_list = [cb_checkpointer, cb_early_stopper]\n",
        "\n",
        "# Model architecture\n",
        "base_model = tf.keras.applications.ResNet50(\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "x = base_model.output\n",
        "x = tf.keras.layers.Reshape((-1, 1, 2048))(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(2, activation='sigmoid')(x)\n",
        "model = tf.keras.Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "# Compiling the model\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['AUC'])\n",
        "\n",
        "# Training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=callbacks_list,\n",
        "    class_weight=train_class_weights\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar o histórico de treinamento em um arquivo separado\n",
        "history_path = '/content/drive/Shareddrives/IA901/dados melanoma/models/history_resnet50.pickle'\n",
        "with open(history_path, 'wb') as f:\n",
        "    pickle.dump(history.history, f)"
      ],
      "metadata": {
        "id": "GFOJf_aF6erG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model_path = '/content/drive/Shareddrives/IA901/dados melanoma/models/'\n",
        "history = load_model(model_path)"
      ],
      "metadata": {
        "id": "-HE3O--2djzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting AUC and loss curves\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Treino')\n",
        "plt.plot(history.history['val_loss'], label='Validação')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Erro')\n",
        "plt.title('Erro de Treinamento e de Validação')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['auc'], label='Treino')\n",
        "plt.plot(history.history['val_auc'], label='Validação')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('AUC')\n",
        "plt.title('AUC de Treinamento e de Validação')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ps0sEjn0bXk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "gBhxPHvp8eaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation and Metrics\n",
        "predictions = model.predict(validation_generator)\n",
        "y_true = validation_generator.classes\n",
        "y_pred = predictions.argmax(axis=1)\n",
        "\n",
        "confusion_mat = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "\n",
        "false_positive_rate = confusion_mat[0, 1] / (confusion_mat[0, 1] + confusion_mat[0, 0])\n",
        "print(\"False Positive Rate:\", false_positive_rate)"
      ],
      "metadata": {
        "id": "vuWGzFCFbbRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "# Obtém as classes reais e as classes previstas\n",
        "y_true = validation_generator.classes\n",
        "y_pred = predictions.argmax(axis=1)\n",
        "\n",
        "# Calcula a matriz de confusão\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot the confusion matrix with total numbers\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.colorbar()\n",
        "\n",
        "# Obtém os rótulos das classes\n",
        "class_names = validation_generator.class_indices\n",
        "class_names = list(class_names.keys())\n",
        "\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names, rotation=45)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "\n",
        "# Calculate the total numbers in each group\n",
        "group_counts = ['{0:0.0f}'.format(value) for value in cm.flatten()]\n",
        "group_percentages = ['{0:.2%}'.format(value) for value in cm.flatten() / np.sum(cm)]\n",
        "\n",
        "# Add the total numbers to the plot\n",
        "labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts, group_percentages)]\n",
        "labels = np.asarray(labels).reshape(cm.shape[0], cm.shape[1])\n",
        "\n",
        "# Show the total numbers in each group\n",
        "thresh = cm.max() / 2.\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, labels[i, j], horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.xlabel('Predito')\n",
        "plt.ylabel('Verdadeiro')\n",
        "plt.title('Matriz de confusão')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "O2yy1oGM-qkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "se2fAxt3NX1j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}